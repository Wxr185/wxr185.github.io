<!DOCTYPE html>


<html lang="zh-CN">
  

    <head>
      <meta charset="utf-8" />
        
      <meta name="description" content="临时的学习笔记，还没有形成个人风格" />
      
      <meta
        name="viewport"
        content="width=device-width, initial-scale=1, maximum-scale=1"
      />
      <title> Alien笔记</title>
  <meta name="generator" content="hexo-theme-ayer">
      
      <link rel="shortcut icon" href="/favicon.ico" />
       
<link rel="stylesheet" href="/dist/main.css">

      
<link rel="stylesheet" href="/css/fonts/remixicon.css">

      
<link rel="stylesheet" href="/css/custom.css">
 
      <script src="https://cdn.staticfile.org/pace/1.2.4/pace.min.js"></script>
       
 

      <link
        rel="stylesheet"
        href="https://cdn.jsdelivr.net/npm/@sweetalert2/theme-bulma@5.0.1/bulma.min.css"
      />
      <script src="https://cdn.jsdelivr.net/npm/sweetalert2@11.0.19/dist/sweetalert2.min.js"></script>

      <!-- mermaid -->
      
      <style>
        .swal2-styled.swal2-confirm {
          font-size: 1.6rem;
        }
      </style>
    </head>
  </html>
</html>


<body>
  <div id="app">
    
      
    <main class="content on">
      
<section class="cover">
    
  <div class="cover-frame">
    <div class="bg-box">
      <img src="/images/cover4.jpg" alt="image frame" />
    </div>
    <div class="cover-inner text-center text-white">
      <h1><a href="/">Alien笔记</a></h1>
      <div id="subtitle-box">
        
        <span id="subtitle"></span>
        
      </div>
      <div>
        
      </div>
    </div>
  </div>
  <div class="cover-learn-more">
    <a href="javascript:void(0)" class="anchor"><i class="ri-arrow-down-line"></i></a>
  </div>
</section>



<script src="https://cdn.staticfile.org/typed.js/2.0.12/typed.min.js"></script>


<!-- Subtitle -->

  <script>
    try {
      var typed = new Typed("#subtitle", {
        strings: ['人生若只如初见，何事秋风悲画扇', '等闲变却故人心，却道故人心易变', '想要的都拥有，得不到的都释怀'],
        startDelay: 0,
        typeSpeed: 200,
        loop: true,
        backSpeed: 100,
        showCursor: true
      });
    } catch (err) {
      console.log(err)
    }
  </script>
  
<div id="main">
  <section class="outer">
  
  
  

<div class="notice" style="margin-top:50px">
    <i class="ri-heart-fill"></i>
    <div class="notice-content" id="broad"></div>
</div>
<script type="text/javascript">
    fetch('https://v1.hitokoto.cn')
        .then(response => response.json())
        .then(data => {
            document.getElementById("broad").innerHTML = data.hitokoto;
        })
        .catch(console.error)
</script>

<style>
    .notice {
        padding: 20px;
        border: 1px dashed #e6e6e6;
        color: #969696;
        position: relative;
        display: inline-block;
        width: 100%;
        background: #fbfbfb50;
        border-radius: 10px;
    }

    .notice i {
        float: left;
        color: #999;
        font-size: 16px;
        padding-right: 10px;
        vertical-align: middle;
        margin-top: -2px;
    }

    .notice-content {
        display: initial;
        vertical-align: middle;
    }
</style>
  
  <article class="articles">
    
    
    
    
    <article
  id="post-LTR/RankNet"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2022/10/06/LTR/RankNet/"
    >RankNet</a> 
</h2>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2022/10/06/LTR/RankNet/" class="article-date">
  <time datetime="2022-10-06T06:40:11.122Z" itemprop="datePublished">2022-10-06</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/LTR/">LTR</a> / <a class="article-category-link" href="/categories/LTR/Pairwise/">Pairwise</a>
  </div>
   
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <p>RankNet是2005年微软提出的一种pairwise的Learning to Rank算法，它从 <strong>概率</strong> 的角度来解决排序问题。RankNet的核心是提出了一种 <strong>概率损失函数来学习Ranking Function</strong>，并应用Ranking Function对文档进行排序。这里的Ranking Function可以是 <strong>任意对参数可微的模型</strong>，也就是说，该概率损失函数并不依赖于特定的机器学习模型，在论文中，RankNet是基于神经网络实现的。除此之外，GDBT等模型也可以应用于该框架。</p>
<p>算法的核心思想：<em><strong>最小化文档对的排序误差</strong></em>。</p>
<h3 id="训练数据"><a href="#训练数据" class="headerlink" title="训练数据"></a>训练数据</h3><p>区别于标准的机器学习的数据结构，<br><img src="/pictures/LTR/RankNet/img1.jpeg" alt="标准的机器学习数据结构"></p>
<p>RankNet做了如下定义，训练样本由 <strong>item对</strong> 构成，最终的训练样本集为：<br><img src="/pictures/LTR/RankNet/img2.png" alt="RankNet数据结构"></p>
<h4 id="样本标签"><a href="#样本标签" class="headerlink" title="样本标签"></a>样本标签</h4><h5 id="预测相关性概率"><a href="#预测相关性概率" class="headerlink" title="预测相关性概率"></a>预测相关性概率</h5><p>对于任意一个doc对(U_i, U_j)，模型输出的score分别为s_i和s_j。那么根据模型的预测，U_i比U_j与Query更相关的概率为：<br><img src="/pictures/LTR/RankNet/img3.png" alt="预测相关性概率"></p>
<p>由于RankNet使用的模型一般为神经网络，根据以往经验，sigmoid函数能够提供一个比较好的概率评估。</p>
<p>RankNet证明了如果知道一个待排序文档的排列中相邻两个文档之间的排序概率，则通过推导可以算出每两个文档之间的排序概率。因此对于一个待排序文档序列，只需计算相邻文档之间的排序概率，不需要计算所有pair，减少计算量。</p>
<h5 id="真实相关性概率"><a href="#真实相关性概率" class="headerlink" title="真实相关性概率"></a>真实相关性概率</h5><p>对于训练数据中的U_i和U_j，它们都包含有一个与Query相关性的真实label，比如U_i与Query的相关性label为good，U_j与Query的相关性label为bad，那么显然U_i比U_j更相关。我们定义U_i比U_j更相关的真实概率为：<br><img src="/pictures/LTR/RankNet/img4.png" alt="真实相关性概率"></p>
<p>在RankNet中类别标签记为S_ij ∈ {+1, -1, 0}。由于接下来要使用交叉熵作为损失函数，因此将标签S_ij与真实概率P_ij（真实相关性）进行上图所示的一一映射。<br>如果U_i比U_j更相关，那么Sij&#x3D;1；如果U_i不如U_j相关，那么S_ij&#x3D;−1；如果U_i、U_j与Query的相关程度相同，那么S_ij&#x3D;0。</p>
<h3 id="假设函数"><a href="#假设函数" class="headerlink" title="假设函数"></a>假设函数</h3><p>f 没有固定的形式，RankNet 设计为两层浅层网络，这也是 RankNet 得名的原因。f 没有固定形式预留了灵活的空间，为后面 LambdaMART 埋下伏笔。<br><img src="/pictures/LTR/RankNet/img8.jpeg" alt="单个样本的交叉熵损失"></p>
<h3 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h3><p>RankNet使用交叉熵作为损失函数，单个样本的交叉熵损失函数为<br><img src="/pictures/LTR/RankNet/img5.png" alt="单个样本的交叉熵损失"></p>
<p>对于一个排序，RankNet从各个doc的相对关系来评价排序结果的好坏，排序的效果越好，那么有错误相对关系的pair就越少。RankNet本质上就是以 <strong>错误的pair最少</strong> 为优化目标。</p>
<p>在抽象成cost function时，RankNet实际上是引入了概率的思想：不是直接判断Ui排在Uj前面，而是说Ui以一定的概率P排在Uj前面，即是以预测概率与真实概率的差距最小作为优化目标。最后，RankNet使用Cross Entropy作为cost function，来衡量P_ij和~P_ij的拟合程度。化简后，有<br><img src="/pictures/LTR/RankNet/img6.png" alt="化简后的交叉熵损失"></p>
<p>下面展示了当S_ij分别取1，0，-1的时候cost function以s_i-s_j为变量的示意图：<br><img src="/pictures/LTR/RankNet/img7.png" alt="损失函数曲线变化"></p>
<p>可以看到当S_ij&#x3D;1时，模型预测的s_i比s_j越大，其代价越小；S_ij&#x3D;−1时，s_i比s_j越小，代价越小；S_ij&#x3D;0时，代价的最小值在s_i与s_j相等处取得。</p>
<p>该损失函数有以下几个特点：</p>
<blockquote>
<ol>
<li>当两个相关性不同的文档算出来的模型分数相同时，损失函数的值大于0，仍会对这对pair做惩罚，使他们的排序位置区分开；</li>
<li>损失函数是一个类线性函数，可以有效减少异常样本数据对模型的影响，因此具有鲁棒性。</li>
</ol>
</blockquote>
<h3 id="优化算法"><a href="#优化算法" class="headerlink" title="优化算法"></a>优化算法</h3><p><img src="/pictures/LTR/RankNet/img9.jpeg" alt="损失函数求偏导数"></p>
<p>损失函数L_ij（上文中表示为C_ij）分别对s_i和s_j求偏微分，可以发现他们之间互为异号，将其定义为lambda：<br><img src="/pictures/LTR/RankNet/img10.jpeg" alt="偏微分互为异号"></p>
<p>根据上述性质，损失函数的梯度可以改写为：<br><img src="/pictures/LTR/RankNet/img11.webp" alt="损失函数的梯度计算"></p>
<p>其中，倒数第三行就是 RankNet 的梯度向量，倒数第二行是 <strong>LambdaRank</strong> 的梯度向量，它在 RankNet 的基础上加上了 <strong>nDCG</strong> 的变化量，在优化的过程中融入了评估指标的信息。 nDCG 本身不可微，这里 <strong>只是计算出这个标量，没有涉及到梯度</strong> 的意思。</p>
<blockquote>
<p>关于这个变化量的绝对值的物理意义，我个人的理解打个不恰当的比喻就是“火上浇油、推波助澜”，如果一个样本对中的两个样本排序悬殊较大，那么互换位置后的变化量也相对较大，就会产生一个较大的梯度信息，告诉算法这俩不是一路人，你要努力地优化让他们进一步拉开差距；而如果两个样本排序悬殊较小，无论是排名靠前还是靠后，都不会产生较大的梯度信息，或者说是给 RankNet 的原始梯度打了一个大大的折扣，告诉算法这俩是“绝代双骄”或者“难兄难弟”，你不用过分地拆散他们。</p>
</blockquote>
<p>最后一行，就是 LambdaMART 的梯度向量，将 Net 换成了 GBDT。</p>
<p>工程上，XGBoost 提供了得天独厚的 LambdaMART 框架，通过指定 objective&#x3D;”rank:map”, eval_metric&#x3D;”map@n” 等参数实现。需要特别注意的是，排序任务需要对 DMatrix 数据结构设置分组信息，使用 set_group() 方法。</p>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/LTR/" rel="tag">LTR</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Pairwise/" rel="tag">Pairwise</a></li></ul>

    </footer>
  </div>

   
    
</article>

    
    <article
  id="post-LTR/Learning-to-Ranking"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2022/10/06/LTR/Learning-to-Ranking/"
    >Learning to Ranking</a> 
</h2>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2022/10/06/LTR/Learning-to-Ranking/" class="article-date">
  <time datetime="2022-10-06T01:56:24.522Z" itemprop="datePublished">2022-10-06</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E6%8E%92%E5%BA%8F%E6%A8%A1%E5%9E%8B/">排序模型</a>
  </div>
   
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <p>参考博客：<a target="_blank" rel="noopener" href="http://it.taocms.org/07/76317.htm">http://it.taocms.org/07/76317.htm</a></p>
<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>Learning to Rank (LTR) 是指一系列基于机器学习的排序算法，最初主要应用于信息检索（Information Retrieval, IR）领域，最典型的是解决搜索引擎对于搜索结果的排序问题。除了信息检索外，Learning to Rank也被应用到许多其他排序问题上，如商品推荐，计算广告，生物信息学等。</p>
<blockquote>
<p>排序学习的定义：基于机器学习中用于解决分类与回归问题的思想，提出利用机器学习方法解决排序的问题。<br>排序学习的目标：自动地从训练数据中学习得到一个排序函数，使其在文本检索中能够针对文本的相关性，重要性等衡量标准对文本进行排序。<br>机器学习的优势：整合大量复杂特征并自动进行参数调整，自动学习最优参数，降低了单一考虑排序因素的风险。同时，能够通过众多有效手段规避过过拟合问题。</p>
</blockquote>
<h3 id="LTR定义"><a href="#LTR定义" class="headerlink" title="LTR定义"></a>LTR定义</h3><p>广义定义：使用机器学习技术来解决ranking问题都统称为LTR方法。<br>狭义定义：满足以下两点的ranking方法：1. Feature Based，样本以特征向量的形式体现；2. Discriminative Training是一个基于训练机的自动学习过程。</p>
<p>一个learning-to-rank方案包括：</p>
<blockquote>
<ol>
<li>输入空间 input space，以特征向量来表示的样本，特诊时以某种方式提取出来的；</li>
<li>输出空间 output space，对input处理后的展现形式，包括以下2种：1. task的最后形式；2. Machine Learning中间便于处理的形式；</li>
<li>假设空间 hypothesis space，定义了一系列从input space到output space的映射函数；</li>
<li>损失函数 loss function，ML的目标就是在training set上定义一个loss function来学习一个optimal hypothesis。</li>
</ol>
</blockquote>
<h3 id="LTR框架"><a href="#LTR框架" class="headerlink" title="LTR框架"></a>LTR框架</h3><p>LTR是 <strong>有监督学习</strong>，因此是需要有标注的training set。经典Learning to Rank框架如下所示。<br><img src="/pictures/LTR/Learning-to-Ranking/img1.png" alt="Learning to rank框架"></p>
<p>排序学习在现代推荐架构中处于非常关键的环节，它可以完成不同召回策略的统一排序，也可将离线、近线、在线的推荐结果根据用户所处的场景进行整合和实时调整，完成打分重排并推荐给用户。美团推荐框架：<br><img src="/pictures/LTR/Learning-to-Ranking/img2.jpeg" alt="美团推荐框架"></p>
<h3 id="LTR的优缺点"><a href="#LTR的优缺点" class="headerlink" title="LTR的优缺点"></a>LTR的优缺点</h3><p>LTR 则是基于特征，通过机器学习算法训练来学习到最佳的拟合公式，相比传统的排序方法，优势有很多：</p>
<blockquote>
<ul>
<li>可以根据反馈自动学习并调整参数</li>
<li>可以融合多方面的排序影响因素</li>
<li>避免过拟合（通过正则项）</li>
<li>实现个性化需求（推荐）</li>
<li>多种召回策略的融合排序推荐（推荐）</li>
<li>多目标学习（推荐）</li>
</ul>
</blockquote>
<p>LTR的局限性：</p>
<blockquote>
<ul>
<li>可解释性差。在一个机器学习的系统当中，人们很难理解为什么一个结果比另一个结果要好。机器学习系统像一个黑盒子，大部分时候告诉我们结果1比结果2更加相关的概率，但不会告诉我们是因为什么原因结果1比结果2要好。</li>
<li>通用性差。很多information retrieval当中发现的特征很难在机器学习模型中产生效果。因为这些特征常常是针对某一类检索问题，然而对于那一类检索问题，常见的机器学习算法可能会为了模型的概括性以及防止overfitting，忽略特定的特征。这也是为什么当有了足够多的ranking engineer，大部分人都会专注改进rule-based scoring方法，去直接针对特定问题进行改进。</li>
</ul>
</blockquote>
<h2 id="Learning-to-Rank算法分类"><a href="#Learning-to-Rank算法分类" class="headerlink" title="Learning to Rank算法分类"></a>Learning to Rank算法分类</h2><p>排序学习模型通常分为三大类：<strong>单点法 Pointwise，配对法 Pairwise，和列表法 Listwise</strong>。<br>三大类的划分并不是特定的算法，而是排序学习模型的设计思路。主要区别体现在 <strong>损失函数</strong> 以及 <strong>相应的标签标注方式和优化方法</strong> 的不同。</p>
<h3 id="单点法-Pointwise"><a href="#单点法-Pointwise" class="headerlink" title="单点法 Pointwise"></a>单点法 Pointwise</h3><p><strong>单点法排序学习模型的每一个训练样本都仅仅是某一个查询关键字和某个文档的配对</strong>。他们之间是否相关，与其他文档和其他查询关键字都没有关系。<strong>单点排序学习是对现实的极大简化</strong>。</p>
<p>单点法将文档转换为特征向量后，机器学习系统根据从训练数据中学习到的分类或者回归函数对文档打分，打分结果即是搜索结果。<br>单点排序学习可以按照标注和损失函数设计的不同，将排序问题转化成回归、分类、和有序分类问题（有些文献也称有序回归）问题。<br><img src="/pictures/LTR/Learning-to-Ranking/img3.png" alt="Pointwise方法"></p>
<p>损失函数的设计思想：</p>
<blockquote>
<ul>
<li>分类（Classification）：输出空间包含的是无序类别，对每个查询-文档对的样本判断是否相关，可以是二分类的，如相关认为是正例，不相关认为是负例；也可以是类似 NDCG 那样的五级标注的多分类问题。分类模型通常会输出一个概率值，可根据概率值的排序作为排序最终结果。</li>
<li>回归（Regression）：输出空间包含的是真实值相关度得分，可通过回归来直接拟合相关度打分。</li>
<li>有序分类（Ordinal Classification）：有序分类也称有序回归（Ordinal Regression），输出空间一般包含的是有序类别，通常的做法是找到一个打分函数，然后用一系列阈值对得分进行分割，得到有序类别。</li>
</ul>
</blockquote>
<h4 id="单点法的应用"><a href="#单点法的应用" class="headerlink" title="单点法的应用"></a>单点法的应用</h4><p>推荐系统领域，最常用的就是二元分类的pointwise，比如常见的点击率CTR预估问题。之所以用的多，是因为二元分类的Pointwise <strong>模型的复杂度</strong> 通常比Pairwise和Listwise低，而且可以 <strong>借助用户的点击反馈自然地完成正负样例的标注</strong>，而其余两者的模型标注比较困难。</p>
<p>Pointwise成功地将排序问题转化为分类问题，也就意味着机器学习中常见的 <strong>分类</strong> 方法都可以直接用来解决排序问题，比如，LR, GBDT, SVM, FM以及结合DNN的各种排序算法。</p>
<h4 id="单点法的缺点"><a href="#单点法的缺点" class="headerlink" title="单点法的缺点"></a>单点法的缺点</h4><p>Pointwise 方法通过优化损失函数求解最优的参数，可以看到 Pointwise 方法非常简单，工程上也易实现，但是 Pointwise 也存在很多问题。</p>
<blockquote>
<ul>
<li>Pointwise只考虑了单个文档同query的相关性，没有考虑文档之间的关系。然而排序最求的排序的结果，只要有相对打分即可；</li>
<li>通过分类知识把不同的文档做了简单的分类，同一类别里的文档无法深入区分；</li>
<li>Pointwise方法并没有考虑同一个query对应的文档间的内部依赖性；</li>
<li>排序结果的 Top N 条的顺序重要性远比剩下全部顺序重要性要高，因为损失函数没有相对排序位置信息，这样会使损失函数可能无意的过多强调那些不重要的 docs。</li>
</ul>
</blockquote>
<h3 id="配对法-Pairwise"><a href="#配对法-Pairwise" class="headerlink" title="配对法 Pairwise"></a>配对法 Pairwise</h3><p>配对法的基本思路是对样本进行两两比较，构建偏序文档对，从比较中学习排序，因为对于一个查询关键字来说，最重要的其实不是针对某一个文档的相关性是否估计得准确，而是要能够正确估计一组文档之间的 “相对关系”。</p>
<p>每一个数据样本其实是一个比较关系，当前一个文档比后一个文档相关排序更靠前的话，就是正例，否则便是负例。</p>
<p>这里面有3个非常关键的假设，</p>
<blockquote>
<ul>
<li>针对某一个关键字得到一个完美的排序关系。在实际操作中，这歌关系可以通过相关标签得到，也可以通过其他信息获得，比如点击率等信息。然而，完美排序关系并不是永远存在的。</li>
<li>通过学习文档之间两两配对关系，从而“重构”这种完美排序。</li>
<li>构建样本来描述这样的两两相对的比较关系。一个相对比较简单的情况，认为文档之间的两两关系来自于文档特征（Feature）之间的差异。也就是说，可以利用样本之间特征的差值当做新的特征，从而学习到差值到相关性差异这样的一组对应关系。</li>
</ul>
</blockquote>
<p>Pairwise 最终的算分，分类和回归都可以实现，不过最常用的还是二元分类。<br><img src="/pictures/LTR/Learning-to-Ranking/img4.png" alt="Pairwise方法"></p>
<h4 id="配对法的应用"><a href="#配对法的应用" class="headerlink" title="配对法的应用"></a>配对法的应用</h4><p>代表算法：</p>
<blockquote>
<ul>
<li>基于 SVM 的 Ranking SVM 算法</li>
<li>基于神经网络的 RankNet 算法（2007）</li>
<li>基于 Boosting 的 RankBoost 算法（2003）</li>
</ul>
</blockquote>
<p>推荐系统中使用较多的 Pairwise 方法是贝叶斯个性化排序（Bayesian personalized ranking，BPR）。</p>
<h4 id="配对法的缺点"><a href="#配对法的缺点" class="headerlink" title="配对法的缺点"></a>配对法的缺点</h4><p>Pairwise 方法通过考虑两两文档之间的相关对顺序来进行排序，相比 Pointwise 方法有明显改善。</p>
<blockquote>
<ul>
<li>使用的是两文档之间相关度的损失函数，而它和真正衡量排序效果的指标之间存在很大不同，甚至可能是负相关的，如可能出现 Pairwise Loss 越来越低，但 NDCG 分数也越来越低的现象。</li>
<li>只考虑了两个文档的先后顺序，且没有考虑文档在搜索列表中出现的位置，导致最终排序效果并不理想。</li>
<li>不同的查询，其相关文档数量差异很大，转换为文档对之后，有的查询可能有几百对文档，有的可能只有几十个，这样不加均一化地在一起学习，模型会优先考虑文档对数量多的查询，减少这些查询的 loss，最终对机器学习的效果评价造成困难。</li>
<li>Pairwise 方法的训练样例是偏序文档对，它将对文档的排序转化为对不同文档与查询相关性大小关系的预测；因此，如果因某个文档相关性被预测错误，或文档对的两个文档相关性均被预测错误，则会影响与之关联的其它文档，进而引起连锁反应并影响最终排序结果。</li>
</ul>
</blockquote>
<h3 id="列表法-Listwise"><a href="#列表法-Listwise" class="headerlink" title="列表法 Listwise"></a>列表法 Listwise</h3><p>Listwise方法是直接优化排序列表，输入为单条样本为一个文档排列。相对于尝试学习每一个样本是否相关或者两个文档的相对比较关系，列表法排序学习的基本思路是尝试直接优化像 NDCG（Normalized Discounted Cumulative Gain）这样的指标，从而能够学习到最佳排序结果。</p>
<p>列表法排序学习有两种基本思路：</p>
<blockquote>
<ul>
<li>第一种称为 Measure-specific，就是直接针对 NDCG 这样的指标进行优化。目的简单明了，用什么做衡量标准，就优化什么目标。</li>
<li>第二种称为 Non-measure specific，则是根据一个已经知道的最优排序，尝试重建这个顺序，然后来衡量这中间的差异。</li>
</ul>
</blockquote>
<p><img src="/pictures/LTR/Learning-to-Ranking/img5.png" alt="Listwise方法"></p>
<h4 id="Measure-specific，直接针对-NDCG-类的排序指标进行优化"><a href="#Measure-specific，直接针对-NDCG-类的排序指标进行优化" class="headerlink" title="Measure-specific，直接针对 NDCG 类的排序指标进行优化"></a>Measure-specific，直接针对 NDCG 类的排序指标进行优化</h4><p>直接优化排序指标的难点在于，希望能够优化 NDCG 指标这样的 “理想” 很美好，但是现实却很残酷。**NDCG、MAP 以及 AUC ** 这类排序标准，都是在数学的形式上的 <strong>“非连续”（Non-Continuous）和 “非可微分”（Non-Differentiable）</strong>。而绝大多数的优化算法都是基于 “连续”（Continuous）和 “可微分”（Differentiable）函数的。因此，直接优化难度比较大。</p>
<p>针对这种情况，主要有这么几种解决方法，</p>
<blockquote>
<ul>
<li>找一个近似 NDCG 的另外一种指标。而这种替代的指标是 “连续” 和 “可微分” 的 。只要我们建立这个替代指标和 NDCG 之间的近似关系，那么就能够通过优化这个替代指标达到逼近优化 NDCG 的目的。这类的代表性算法的有 SoftRank 和 AppRank。</li>
<li>尝试从数学的形式上写出一个 NDCG 等指标的 “边界”（Bound），然后优化这个边界。比如，如果推导出一个上界，那就可以通过最小化这个上界来优化 NDCG。这类的代表性算法有 SVM-MAP 和 SVM-NDCG。</li>
<li>希望从优化算法上下手，看是否能够设计出复杂的优化算法来达到优化 NDCG 等指标的目的。对于这类算法来说，算法要求的目标函数可以是 “非连续” 和 “非可微分” 的。这类的代表性算法有 AdaRank 和 RankGP。</li>
</ul>
</blockquote>
<h4 id="Non-measure-specific，尝试重建最优顺序，衡量其中差异"><a href="#Non-measure-specific，尝试重建最优顺序，衡量其中差异" class="headerlink" title="Non-measure specific，尝试重建最优顺序，衡量其中差异"></a>Non-measure specific，尝试重建最优顺序，衡量其中差异</h4><p>这种思路的主要假设是，已经知道了针对某个搜索关键字的完美排序，那么怎么通过学习算法来逼近这个完美排序。我们希望缩小预测排序和完美排序之间的差距。值得注意的是，在这种思路的讨论中，优化 NDCG 等排序的指标并不是主要目的。这里面的代表有 ListNet 和 ListMLE。</p>
<h4 id="列表法和配对法的中间解法"><a href="#列表法和配对法的中间解法" class="headerlink" title="列表法和配对法的中间解法"></a>列表法和配对法的中间解法</h4><p>这类思路的核心思想，是从 NDCG 等指标中受到启发，设计出一种替代的目标函数，把直接优化列表的想法退化成优化某种配对。这个方向的代表方法就是微软发明的 LambdaRank 以及后来的 LambdaMART。</p>
<h4 id="列表法的应用"><a href="#列表法的应用" class="headerlink" title="列表法的应用"></a>列表法的应用</h4><p>代表算法：</p>
<blockquote>
<ul>
<li>基于 Measure-specific 的 SoftRank、SVM-MAP、SoftRank、LambdaRank、LambdaMART</li>
<li>基于 Non-measure specific 的 ListNet、ListMLE、BoltzRank。</li>
</ul>
</blockquote>
<p>推荐中使用较多的 Listwise 方法是 LambdaMART。</p>
<h4 id="列表法的缺点"><a href="#列表法的缺点" class="headerlink" title="列表法的缺点"></a>列表法的缺点</h4><p>列表法相较单点法和配对法针对排序问题的模型设计更加自然，解决了排序应该基于 query 和 position 问题。</p>
<blockquote>
<ul>
<li>一些算法需要基于排列来计算 loss，从而使得训练复杂度较高，如 ListNet 和 BoltzRank。</li>
<li>位置信息并没有在 loss 中得到充分利用，可以考虑在 ListNet 和 ListMLE 的 loss 中引入位置折扣因子。</li>
</ul>
</blockquote>
<h2 id="Learning-to-Ranking评估指标"><a href="#Learning-to-Ranking评估指标" class="headerlink" title="Learning to Ranking评估指标"></a>Learning to Ranking评估指标</h2><h3 id="P-K-Precision-at-K"><a href="#P-K-Precision-at-K" class="headerlink" title="P@K (Precision at K)"></a>P@K (Precision at K)</h3><p>对于现在的大规模 IR 任务，每个 query 都有大量相关的 doc，因此很难再用查全率进行衡量召回质量，但是可以用 Precision at K 对召回质量进行评价。</p>
<p>Precision at K 通常表示为 P@K， 表示 top-k 的结果中有相关结果所占比例，其中 K 表示前 K 位.</p>
<blockquote>
<p>比如，一个模型输出了一组排序，其输出的好坏依次为：好、坏、好、坏、好。那么，</p>
<ul>
<li>Prec@3 &#x3D; 2&#x2F;3</li>
<li>Prec@4 &#x3D; 2&#x2F;4</li>
<li>Prec@5 &#x3D; 3&#x2F;5</li>
</ul>
</blockquote>
<h3 id="MAP-Mean-Average-Precision"><a href="#MAP-Mean-Average-Precision" class="headerlink" title="MAP (Mean Average Precision)"></a>MAP (Mean Average Precision)</h3><p>在二分类中，常常使用Precision, Recall, ROC 曲线，AUC来评价一个模型的性能，然而这些指标很难对多分类模型进行准确的评价。</p>
<p>AP 是指的在所有Recall的可能取值情况下，得到的所有的Precision的平均值。AP衡量的是我们训练得到的模型在每个类别上的好坏，MAP衡量的是该模型在所有类别上的好坏，得到AP后，MAP的计算就变得很简单了，就是取所有AP的平均值。</p>
<p>MAP（Mean Average Precision）是信息检中的一个评价指标。MAP假定相关度有两个级别 —— 相关与不相关。 首先了解下AP（Average Precision）计算方法：<br><img src="/pictures/LTR/Learning-to-Ranking/img6.png" alt="AP的计算公式"></p>
<p>上式中，k为文档在排序列表中的位置，p(k) 为前k个结果的准确率，rel(k)表示位置k的文档是否相关，相关为1，不相关为0。MAP为一组查询AP的平均值。</p>
<blockquote>
<p>假设有两个主题，主题1有4个相关网页，主题2有5个相关网页。某系统对于主题1检索出4个相关网页，其rank分别为1, 2, 4, 7；对于主题2检索出3个相关网页，其rank分别为1,3,5。对于主题1，平均准确率为(1&#x2F;1+2&#x2F;2+3&#x2F;4+4&#x2F;7)&#x2F;4&#x3D;0.83。对于主题2，平均准确率为(1&#x2F;1+2&#x2F;3+3&#x2F;5+0+0)&#x2F;5&#x3D;0.45。则MAP&#x3D; (0.83+0.45)&#x2F;2&#x3D;0.64。</p>
</blockquote>
<h4 id="MAP优点"><a href="#MAP优点" class="headerlink" title="MAP优点"></a>MAP优点</h4><blockquote>
<ul>
<li>给出了一个代表精确度—召回率曲线下复杂区域的单一度量。这提供了每个列表的平均精度。</li>
<li>处理列表推荐物品的自然排序。这与将检索项视为集合的度量标准形成了对比。</li>
<li>这一指标能够给予发生在排序高的推荐名单中的错误更多的权重。相反，它对发生在推荐列表中较深位置的错误的权重较小。这符合在推荐列表的最前面显示尽可能多的相关条目的需要。</li>
</ul>
</blockquote>
<h4 id="MAP缺点"><a href="#MAP缺点" class="headerlink" title="MAP缺点"></a>MAP缺点</h4><blockquote>
<ul>
<li>这个度量标准适用于二进制(相关&#x2F;非相关)评级。然而，它不适合细粒度的数字评级。此度量无法从此信息中提取误差度量。</li>
<li>对于细粒度的评分，例如从 1 星到 5 星的评分，评估首先需要对评分进行阈值，以产生二元相关性。一种选择是只考虑大于 4 的评级。由于人工阈值的存在，这在评估度量中引入了偏差。</li>
</ul>
</blockquote>
<h3 id="NDGG-Normalized-Discounted-Cumulative-Gain"><a href="#NDGG-Normalized-Discounted-Cumulative-Gain" class="headerlink" title="NDGG (Normalized Discounted Cumulative Gain)"></a>NDGG (Normalized Discounted Cumulative Gain)</h3><p>在MAP中相关度只有相关、不相关两个级别。NDCG则可以定义多级相关度，相关度级别更高的文档排序更靠前。</p>
<h4 id="DCG-Discounted-Cumulative-Gain，-折扣累计增益"><a href="#DCG-Discounted-Cumulative-Gain，-折扣累计增益" class="headerlink" title="DCG (Discounted Cumulative Gain， 折扣累计增益)"></a>DCG (Discounted Cumulative Gain， 折扣累计增益)</h4><p>DCG， Discounted 的CG，就是在每一个CG的结果上处以一个折损值，为什么要这么做呢？目的就是为了让排名越靠前的结果越能影响最后的结果。</p>
<p>DCG认为应对出现在排序列表中靠后的文档进行惩罚，因此 <strong>文档相关度与其所在位置的对数成反比</strong>。 只考虑前P个文档，DCG定义为：<br><img src="/pictures/LTR/Learning-to-Ranking/img7.png" alt="DCG计算公式"></p>
<p>其中，rel_i 为位置i上文档的相关度得分，1 &#x2F; log_2(i+1)为折算因子。</p>
<p>DCG还有另外一种定义，也被经常使用。该定义 <strong>更加强调检索相关度高的文档</strong>，被广泛应用于网络搜索公司和Kaggle等机器学习竞赛中。<br><img src="/pictures/LTR/Learning-to-Ranking/img8.png" alt="DCG另一种计算公式"></p>
<h4 id="NDCG计算公式"><a href="#NDCG计算公式" class="headerlink" title="NDCG计算公式"></a>NDCG计算公式</h4><p>因为 <strong>不同的搜索结果列表长度可能有所不同</strong>，因此不能用DCG对不同搜索结果进行对比，需要 <strong>对DCG值进行归一化</strong>，即需要用到下面介绍的NDCG。首先计算位置最大可能的DCG，即理想情况的DCG（IDCG）【正确的排序结果】。</p>
<h4 id="NDCG计算例子"><a href="#NDCG计算例子" class="headerlink" title="NDCG计算例子"></a>NDCG计算例子</h4><p>假设查询q的结果列表包含5个文档，分别为D_1,..,D_5，相关度取值为1、2、3；这五个文档的相关度rel_i分别为：3、1、3、2、2；对每个文档计算 log_2(i+1) 和 rel_i &#x2F; log_2(i+1)。<br><img src="/pictures/LTR/Learning-to-Ranking/img9.png" alt="预测后前5个结果计算DCG"></p>
<p>假设处理查询结果的5个文档，另外还返回了两个文档D_6, D_7其相关度为3、1。则对这7个文档按照相关度进行排序有：3、3、3、2、2、1, 1。计算得到 <strong>按照相关性从大到小排序</strong> 后结果 IDCG_5&#x3D;8.028</p>
<p>最终计算结果为：NDCG_5 &#x3D; DCG_5 &#x2F; IDCG_5 &#x3D; 0.843</p>
<h4 id="NDCG优缺点"><a href="#NDCG优缺点" class="headerlink" title="NDCG优缺点"></a>NDCG优缺点</h4><blockquote>
<ul>
<li>NDCG 的主要优势是它考虑到了分等级的相关性值。当它们在数据集中可用时，NDCG 是一个很好的选择。</li>
<li>与 MAP 度量相比，它在评估排名项目的位置方面做得很好。它适用于二元的相关&#x2F;非相关场景。</li>
<li>平滑的对数折现因子有一个很好的理论基础，该工作的作者表明，对于每一对显著不同的排名推荐系统，NDCG 度量始终能够确定更好的一个。</li>
</ul>
</blockquote>
<blockquote>
<ul>
<li>NDCG 在部分反馈方面有一些问题。当我们有不完整的评级时，就会发生这种情况。这是大多数推荐系统的情况。如果我们有完整的评级，就没有真正的任务去实现！在这种情况下，recsys 系统所有者需要决定如何归罪于缺失的评级。将缺少的值设置为 0 将把它们标记为不相关的项。其他计算值(如用户的平均&#x2F;中值)也可以帮助解决这个缺点。</li>
<li>接下来，用户需要手动处理 IDCG 等于 0 的情况。当用户没有相关文档时，就会发生这种情况。这里的一个策略是也将 NDCG 设置为 0。</li>
<li>另一个问题是处理 NDCG@K。recsys 系统返回的排序列表的大小可以小于 k。为了处理这个问题，我们可以考虑固定大小的结果集，并用最小分数填充较小的集合。</li>
</ul>
</blockquote>
<h3 id="MRR-Mean-Reciprocal-Rank"><a href="#MRR-Mean-Reciprocal-Rank" class="headerlink" title="MRR (Mean Reciprocal Rank)"></a>MRR (Mean Reciprocal Rank)</h3><p>平均倒数排名（Mean Reciprocal Rank, MRR）是一个国际上通用的对搜索算法进行评价的机制，其评估假设是 <strong>基于唯一的一个相关结果</strong>，即第一个结果匹配，分数为 1 ，第二个匹配分数为 0.5，第 n 个匹配分数为 1&#x2F;n，如果没有匹配的句子分数为0。最终的分数为所有得分之和。</p>
<p>指标反应的是我们找到的这些item是否摆在用户更明显的位置，强调位置关系，顺序性。公式如下，N表示推荐次数， <strong>1&#x2F;p表示用户真实访问的item在结果列表中的排名位置</strong>，如果没在结果序列中，则p为无穷大，1&#x2F;p为0。<br><img src="/pictures/LTR/Learning-to-Ranking/img10.png" alt="MRR计算公式"></p>
<p>如对于第一个 Query，查询结果将正确结果排名 rank 为 3，则其 Reciprocal Rank 为 1&#x2F;3，对于第二个 Query，查询结果将正确结果排名 rank 为 2，则其 Reciprocal Rank 为 1&#x2F;2，对于第三个 Query，查询结果将正确结果排名 rank 为 1，则其 Reciprocal Rank 为 1，则 MRR &#x3D; (1&#x2F;3 + 1&#x2F;2 + 1)&#x2F;3 &#x3D; 11&#x2F;18 &#x3D; 0.61。</p>
<h4 id="MRR优缺点"><a href="#MRR优缺点" class="headerlink" title="MRR优缺点"></a>MRR优缺点</h4><blockquote>
<ul>
<li>该方法计算简单，解释简单。</li>
<li>这种方法高度关注列表的第一个相关元素。它最适合有针对性的搜索，比如用户询问“对我来说最好的东西”。</li>
<li>适用于已知项目搜索，如导航查询或寻找事实。</li>
</ul>
</blockquote>
<blockquote>
<ul>
<li>MRR 指标不评估推荐项目列表的其余部分。它只关注列表中的第一个项目。</li>
<li>它给出一个只有一个相关物品的列表。如果这是评估的目标，那找个度量指标是可以的。</li>
<li>对于想要浏览相关物品列表的用户来说，这可能不是一个好的评估指标。用户的目标可能是比较多个相关物品。</li>
</ul>
</blockquote>
<h3 id="ERR-Expected-Reciprocal-Rank"><a href="#ERR-Expected-Reciprocal-Rank" class="headerlink" title="ERR (Expected Reciprocal Rank)"></a>ERR (Expected Reciprocal Rank)</h3><p>倒序排名期望ERR是受到cascade model的启发。点击模型中的cascade model，考虑到在同一个检索结果列表中各文档之间的位置依赖关系，假设用户从上至下查看，如果遇到某一检索结果项满意并进行点击，则操作结束；否则跳过该项继续往后查看。</p>
<p>ERR (倒数排名的期望)，表示用户的需求被满足时停止的位置的倒数的期望，与 MRR 计算第一个相关文档的位置倒数不同。</p>
<h4 id="Cascade-Models"><a href="#Cascade-Models" class="headerlink" title="Cascade Models"></a>Cascade Models</h4><p>之前的评分模型虽然考虑了 <strong>位置自身的价值信息</strong> 和 <strong>位置上文档的相关度信息</strong>，但是没有考虑 <strong>文档之间</strong> 的相关性信息。</p>
<blockquote>
<p>一种考虑是，一个文档是否被用户点击和排在它前面的文档有很大的关系，比如排在前面的文档都是不相关文档，那么它被点击的概率就高，如果排它前面的文档都是非常相关的文档，那么它被点击的概率就很低。</p>
</blockquote>
<p>Cascade Models假设用户从排名由高到底依次查看文档，一旦文档满足了用户的需求，则停止查看后续的文档。用R_i表示用户只看在位置i上的文档后就不在需要查看其它文档的概率，显然文档的相关度越高，R_i越大。那么用户在位置 r 停止的概率公式如下：<br><img src="/pictures/LTR/Learning-to-Ranking/img11.png" alt="用户在位置r处停止的概率公式"></p>
<h4 id="ERR计算公式"><a href="#ERR计算公式" class="headerlink" title="ERR计算公式"></a>ERR计算公式</h4><p>区别于上述计算公式，R_i是关于文档相关度等级的函数，可以取如下的函数，其中g表示原始的相关度等级：<br><img src="/pictures/LTR/Learning-to-Ranking/img12.png" alt="文档相关度等级函数"></p>
<p>那么ERR计算公式如下：<br><img src="/pictures/LTR/Learning-to-Ranking/img13.png" alt="ERR计算公式"></p>
<h4 id="ERR优缺点"><a href="#ERR优缺点" class="headerlink" title="ERR优缺点"></a>ERR优缺点</h4><blockquote>
<p>NDCG和ERR指标的优势在于，它们对doc的相关性划分多个（&gt;2）等级，而MRR和MAP只会对doc的相关性划分2个等级（相关和不相关）。并且，这些指标都包含了doc位置信息（给予靠前位置的doc以较高的权重），这很适合于web search。</p>
</blockquote>
<blockquote>
<p>然而，这些指标的缺点是不平滑、不连续，无法求梯度，如果将这些指标直接作为模型评分的函数的话，是无法直接用梯度下降法进行求解的。</p>
</blockquote>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/LTR/" rel="tag">LTR</a></li></ul>

    </footer>
  </div>

   
    
</article>

    
    <article
  id="post-NLP/RoBERTa"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2022/10/05/NLP/RoBERTa/"
    >RoBERTa</a> 
</h2>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2022/10/05/NLP/RoBERTa/" class="article-date">
  <time datetime="2022-10-05T03:32:52.653Z" itemprop="datePublished">2022-10-05</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/">自然语言处理</a>
  </div>
   
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <p>参考博客：<a target="_blank" rel="noopener" href="https://blog.csdn.net/Decennie/article/details/120010025">https://blog.csdn.net/Decennie/article/details/120010025</a></p>
<h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>RoBERTa 模型是BERT 的改进版(A Robustly Optimized BERT，即简单粗暴称为强力优化的BERT方法)。</p>
<p>在 <strong>模型规模、算力和数据</strong> 上，与BERT相比主要有以下几点改进：</p>
<blockquote>
<ol>
<li>更大的模型参数量（论文提供的训练时间来看，模型使用 1024 块 V100 GPU 训练了 1 天的时间）</li>
<li>更大bacth size。RoBERTa 在训练过程中使用了更大的bacth size。尝试过从 256 到 8000 不等的bacth size。</li>
<li>更多的训练数据（包括：CC-NEWS 等在内的 160GB 纯文本。而最初的BERT使用16GB BookCorpus数据集和英语维基百科进行训练）</li>
</ol>
</blockquote>
<p>另外，RoBERTa在 <strong>训练方法</strong> 上有以下改进：</p>
<blockquote>
<ol>
<li>去掉下一句预测(NSP)任务</li>
<li>动态掩码。BERT 依赖随机掩码和预测 token。原版的 BERT 实现在数据预处理期间执行一次掩码，得到一个静态掩码。 而 RoBERTa 使用了动态掩码：每次向模型输入一个序列时都会生成新的掩码模式。这样，在大量数据不断输入的过程中，模型会逐渐适应不同的掩码策略，学习不同的语言表征。</li>
<li>文本编码。Byte-Pair Encoding（BPE）是字符级和词级别表征的混合，支持处理自然语言语料库中的众多常见词汇。原版的 BERT 实现使用字符级别的 BPE 词汇，大小为 30K，是在利用启发式分词规则对输入进行预处理之后学得的。Facebook 研究者没有采用这种方式，而是考虑用更大的 byte 级别 BPE 词汇表来训练 BERT，这一词汇表包含 50K 的 subword 单元，且没有对输入作任何额外的预处理或分词。</li>
</ol>
</blockquote>
<h3 id="对于NSP任务的解析和改用"><a href="#对于NSP任务的解析和改用" class="headerlink" title="对于NSP任务的解析和改用"></a>对于NSP任务的解析和改用</h3><p>NSP这个任务在预训练类型的训练中，一直被人诟病，觉得作用不大。SpanBERT文章,也弃用了NSP，而是 <strong>直接把上下句当成一个长句的语料</strong>，进行训练。觉得超长句语料可以让预训练模型学习的更好（这个观点其实在Roberta里实验里论证过了，更长的句子更利于模型获取更多上下文的信息，利于模型参数训练）。</p>
<p>关于NSP为什么作用不大，可能有以下原因：</p>
<blockquote>
<ol>
<li>超长句相比于NSP上下句的分割模式，利于模型学习更长上下文信息，也利于模型参数训练（但这也必然带来训练的时间、开销变大）；</li>
<li>在 NSP 的负例构造，上下句来自于不同的文档组装，会给 MLM 任务带来很大噪音。</li>
</ol>
</blockquote>
<h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><p>RoBERTa建立在BERT的语言掩蔽策略的基础上，修改BERT中的关键超参数，包括 <strong>删除BERT的下一个句子训练前目标</strong>，以及 <strong>使用更大的bacth size和学习率进行训练</strong>。RoBERTa也接受了比BERT多一个数量级的训练，时间更长。这使得RoBERTa表示能够比BERT更好地推广到下游任务。</p>
<h2 id="实验设置"><a href="#实验设置" class="headerlink" title="实验设置"></a>实验设置</h2><h3 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h3><p>在 DGX-1 机器上使用混合精度浮点算法进行训练，每台机器都有 8×32GB Nvidia V100 GPU。</p>
<h3 id="数据"><a href="#数据" class="headerlink" title="数据"></a>数据</h3><p>RoBERTa 采用 160 G 训练文本，远超 BERT 的 16G 文本，其中包括：</p>
<blockquote>
<ol>
<li>BOOKCORPUS 和英文维基百科：原始 BERT 的训练集，大小 16GB。</li>
<li>CC-NEWS：包含2016年9月到2019年2月爬取的6300万篇英文新闻，大小 76 GB（经过过滤之后）。</li>
<li>OPENWEBTEXT：从 Reddit 上共享的 URL （至少3个点赞）中提取的网页内容，大小 38 GB 。</li>
<li>STORIES：CommonCrawl 数据集的一个子集，包含 Winograd 模式的故事风格，大小 31GB 。</li>
</ol>
</blockquote>
<h3 id="评估"><a href="#评估" class="headerlink" title="评估"></a>评估</h3><p>使用以下三个基准评估下游任务的预训练模型:</p>
<blockquote>
<ol>
<li>GLUE 通用语言理解评估（GLUE）基准是用于评估自然语言理解系统的 9 个数据集的集合。</li>
<li>SQuAD 斯坦福问题答疑数据集（SQuAD）提供了一段背景和一个问题。任务是通过从上下文中提取相关跨度来回答问题。</li>
<li>RACE 考试的重新理解（RACE）任务是一个大型阅读理解数据集，有超过 28000 个段落和近100000 个问题。该数据集来自中国的英语考试，专为中学生和高中生设计。</li>
</ol>
</blockquote>
<h2 id="训练过程分析"><a href="#训练过程分析" class="headerlink" title="训练过程分析"></a>训练过程分析</h2><p>本节探讨在保持模型架构不变的情况下，哪些量化指标对预训练BERT模型有影响。首先维持训练BERT模型架构不变，其配置与BERT-base相同（L &#x3D; 12， H &#x3D; 768， A &#x3D; 12，110M 参数）。</p>
<h3 id="静态-VS-动态mask"><a href="#静态-VS-动态mask" class="headerlink" title="静态 VS 动态mask"></a>静态 VS 动态mask</h3><h4 id="原始静态mask"><a href="#原始静态mask" class="headerlink" title="原始静态mask"></a>原始静态mask</h4><p>BERT中是预处理训练数据时，每个样本只会进行 <strong>一次随机mask</strong> （因此每个epoch都是重复），后续的每个训练步都采用相同的mask，这是原始静态mask，即单个静态mask，这是原始 BERT 的做法。</p>
<h4 id="修改版静态mask"><a href="#修改版静态mask" class="headerlink" title="修改版静态mask"></a>修改版静态mask</h4><p>在预处理的时候将数据集 <strong>拷贝 10 次</strong>，每次拷贝采用 <strong>不同的 mask</strong>（总共40 epochs，所以每一个mask对应的数据被训练4个epoch）。这等价于 <strong>原始的数据集采用10种静态 mask 来训练 40个 epoch</strong>。</p>
<h4 id="动态mask"><a href="#动态mask" class="headerlink" title="动态mask"></a>动态mask</h4><p>并没有在预处理的时候执行 mask，而是在 <strong>每次向模型提供输入时动态生成 mask</strong> ，所以是时刻变化的。</p>
<h4 id="实验结论"><a href="#实验结论" class="headerlink" title="实验结论"></a>实验结论</h4><p>不同模式的实验效果如下表所示。其中 reference 为BERT 用到的原始静态 mask，static 为修改版的静态mask。<br><img src="/pictures/NLP/RoBERTa/img1.png" alt="静态VS动态mask效果对比"></p>
<p>从Table1中可以看出，修改版的静态mask与BERT原始静态mask效果相当；动态mask又与静态mask效果差不多，或者说略好了静态mask。基于上述结果的判断，及其动态mask在效率上的优势，<strong>本文后续的实验统一采用动态mask</strong>。</p>
<h3 id="Model-Input-Format-and-NSP"><a href="#Model-Input-Format-and-NSP" class="headerlink" title="Model Input Format and NSP"></a>Model Input Format and NSP</h3><p>原始的BERT包含2个任务，预测被mask掉的单词和下一句预测。鉴于最近有研究(Lample and Conneau,2019; Yang et al., 2019; Joshi et al., 2019)开始质疑下一句预测(NSP)的必要性，本文设计了以下4种训练方式：</p>
<h4 id="SEGMENT-PAIR-NSP"><a href="#SEGMENT-PAIR-NSP" class="headerlink" title="SEGMENT-PAIR + NSP"></a>SEGMENT-PAIR + NSP</h4><p>输入包含两部分，每个部分是来自同一文档或者不同文档的 segment （segment 是连续的多个句子），这两个segment 的token总数少于 512 。预训练包含 MLM 任务和 NSP 任务。这是原始 BERT 的做法。</p>
<h4 id="SENTENCE-PAIR-NSP"><a href="#SENTENCE-PAIR-NSP" class="headerlink" title="SENTENCE-PAIR + NSP"></a>SENTENCE-PAIR + NSP</h4><p>输入也是包含两部分，每个部分是来自同一个文档或者不同文档的单个句子，这两个句子的token 总数少于 512 。由于这些输入明显少于512 个tokens，因此增加batch size的大小，以使 tokens 总数保持与SEGMENT-PAIR + NSP 相似。预训练包含 MLM 任务和 NSP 任务。</p>
<h4 id="FULL-SENTENCES"><a href="#FULL-SENTENCES" class="headerlink" title="FULL-SENTENCES"></a>FULL-SENTENCES</h4><p>输入只有一部分（而不是两部分），来自同一个文档或者不同文档的连续多个句子，token 总数不超过 512 。输入可能跨越文档边界，如果跨文档，则在上一个文档末尾添加文档边界token 。预训练不包含 NSP 任务。</p>
<h4 id="DOC-SENTENCES"><a href="#DOC-SENTENCES" class="headerlink" title="DOC-SENTENCES"></a>DOC-SENTENCES</h4><p>输入只有一部分（而不是两部分），输入的构造类似于FULL-SENTENCES，只是不需要跨越文档边界，其输入来自同一个文档的连续句子，token 总数不超过 512 。在文档末尾附近采样的输入可以短于 512个tokens， 因此在这些情况下动态增加batch size大小以达到与 FULL-SENTENCES 相同的tokens总数。预训练不包含 NSP 任务。</p>
<h4 id="实验结论-1"><a href="#实验结论-1" class="headerlink" title="实验结论"></a>实验结论</h4><p><img src="/pictures/NLP/RoBERTa/img2.png" alt="训练方式对比"></p>
<p>BERT采用 <strong>SEGMENT-PAIR</strong> 输入格式。如果在采用NSP loss情况下，SEGMENT-PAIR优于SENTENCE-PAIR。单个句子会损害下游任务，可能是因为句子过短，模型没有充分学习。</p>
<p>在不采用NSP loss情况下，用来自单个文档的文本块进行训练。该设置性能优于最初发布的BRRT-base结果。与原始BERT相比，去掉NSP损失能够使得下游任务的表现持平或者略微升高。</p>
<p>实验还发现将序列限制为来自单个文档(DOC-SENTENCES)的性能略好于序列来自多个文档(FULL-SENTENCES)。</p>
<h3 id="Training-with-large-batches"><a href="#Training-with-large-batches" class="headerlink" title="Training with large batches"></a>Training with large batches</h3><p>通过梯度累积，训练batch size&#x3D;2K序列的125K步，或batch size&#x3D;8K的31K步，这两者在计算成本上大约是是等价的。</p>
<p>large batches训练提高了masked language modeling 目标的困惑度，以及最终任务的准确性。large batches也更容易分布式数据并行训练， 在后续实验中，文本使用bacth size&#x3D;8K进行并行训练。</p>
<h3 id="Text-Encoding"><a href="#Text-Encoding" class="headerlink" title="Text Encoding"></a>Text Encoding</h3><p>字节对编码(BPE)(Sennrich et al.,2016)是字符级和单词级表示的混合，该编码方案可以处理自然语言语料库中常见的大量词汇。BPE不依赖于完整的单词，而是依赖于子词(sub-word)单元，这些子词单元是通过对训练语料库进行统计分析而提取的，其词表大小通常在 1万到 10万之间。当对海量多样语料建模时，unicode characters占据了该词表的大部分。</p>
<blockquote>
<p>基于 char-level ：原始 BERT 的方式，它通过对输入文本进行启发式的词干化之后处理得到。<br>基于 bytes-level：与 char-level 的区别在于bytes-level 使用 bytes 而不是 unicode 字符作为 sub-word 的基本单位，因此可以编码任何输入文本而不会引入 UNKOWN 标记。</p>
</blockquote>
<p>当采用 bytes-level 的 BPE 之后，词表大小从3万（原始 BERT 的 char-level ）增加到5万。这分别为 BERT-base和 BERT-large增加了1500万和2000万额外的参数。</p>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/NLP/" rel="tag">NLP</a></li></ul>

    </footer>
  </div>

   
    
</article>

    
    <article
  id="post-NLP/Word2Vec"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2022/09/25/NLP/Word2Vec/"
    >Word2Vec</a> 
</h2>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2022/09/25/NLP/Word2Vec/" class="article-date">
  <time datetime="2022-09-25T07:53:50.532Z" itemprop="datePublished">2022-09-25</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/">自然语言处理</a>
  </div>
   
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <h3 id="什么是Word2Vec"><a href="#什么是Word2Vec" class="headerlink" title="什么是Word2Vec?"></a>什么是Word2Vec?</h3><p>Word2Vec模型实际上分了两个部分，第一部分建立模型，第二部分通过模型获取嵌入词向量。<br>Word2Vec的整个建模过程实际上与自编码器的思想很相似。</p>
<blockquote>
<p>先基于训练数据构建神经网络。当模型训练好以后，我们并不会使用这个训练好的模型处理新的任务，我们需要的是通过训练数据学习得到的参数，例如隐层的权重矩阵。</p>
</blockquote>
<p>Word2Vec的训练模型本质上是只具有一个隐含层的神经元网络，从大量文本语料中以无监督的方式学习语义知识。<br><img src="/pictures/NLP/Word2Vec/img1.jpg.png" alt="Word2Vec单层网络结构"></p>
<blockquote>
<ul>
<li>输入是One-Hot向量，Hidden Layer的激活函数是线性。Output Layer维度和Input Layer维度相同，用的是Softmax回归；</li>
<li>训练Word2Vec需要用到反向传播算法，本质是链式求导；</li>
<li>我们并不关心模型训练任务，我们真正需要的是这个模型通过学习得到的参数，即隐层的权重矩阵；</li>
<li>Word2Vec本质是一种降维操作。</li>
</ul>
</blockquote>
<p>Word2Vec其实就是通过学习文本来用词向量的方式表征词的语义信息，即通过一个嵌入空间是的语义相似的单词在该空间内距离很近。<br><strong>Embedding</strong> 其实就是一个映射，将单词从原先所属的空间映射到新的多维空间中。通过对词汇表中单词进行这种数值表示方式的学习，能够进行 <em><strong>向量化</strong></em> 的操作。  </p>
<h3 id="模型结构"><a href="#模型结构" class="headerlink" title="模型结构"></a>模型结构</h3><p>Word2Vec模型中，主要有两种结构：</p>
<blockquote>
<ul>
<li><strong>CBOW模型</strong> ：训练输入是某一个特征词的上下文相关的词对应的词向量，而输出就是这特定的一个词的词向量；  </li>
<li><strong>Skip-gram模型</strong> ：输入是特定的一个词的词向量，而输出是特定词对应的上下文词向量；</li>
</ul>
</blockquote>
<p><img src="/pictures/NLP/Word2Vec/img2.png" alt="Word2Vec网络结构"></p>
<h4 id="Skip-gram"><a href="#Skip-gram" class="headerlink" title="Skip-gram"></a>Skip-gram</h4><p>Skip-gram模型，通过中间词预测上下文。</p>
<ul>
<li>首先，选择句子中的一个词作为中心词；</li>
<li>定义skip_window参数，限制从中心词左右可以选词的范围；</li>
<li>神经网络基于这些训练数据将会输出一个概率分布，这个概率代表词典中每个词是上下文的可能性。</li>
</ul>
<p>训练样本的构成是通过选择输入词前后skip_window范围内的词语与输入词进行组合。下图中，蓝色代表input word，方框内代表位于窗口内的单词。<br><img src="/pictures/NLP/Word2Vec/img5.png" alt="训练样本构建"><br>模型将会从每对单词出现的次数中学习得到统计规律。</p>
<p>以下是Skip-gram模型结构：<br><img src="/pictures/NLP/Word2Vec/img3.png" alt="Skip-gram网络结构"><br>隐层没有使用任何激活函数，但是输出层使用了softmax。<br>我们基于成对的单词来对神经网络进行训练，训练样本是上述单词对，其中input word和output word都是onehot向量。最终模型输出是一个概率分布。</p>
<blockquote>
<p>可以看成y &#x3D; f(x)模型的并联，cost function是单个cost function的累加 <strong>（取log之后）</strong>。</p>
</blockquote>
<h4 id="CBOW"><a href="#CBOW" class="headerlink" title="CBOW"></a>CBOW</h4><p><img src="/pictures/NLP/Word2Vec/img4.jpg" alt="CBOW网络结构"><br>注意到，跟Skip-gram模型的并联不同，CBOW输入要对多个单词进行输入处理，一般是求和然后平均，输出的cost function不变。</p>
<blockquote>
<ol>
<li>输入层：上下文单词的one-hot向量表示；</li>
<li>所有one-hot向量分别乘以共享的输入权重矩阵W；</li>
<li>所得的向量 <strong>相加求平均</strong> 作为隐层向量；</li>
<li>乘以输出矩阵W’；</li>
<li>得到向量，经过softmax函数处理得到V-dim概率分布；</li>
<li>概率最大的index所指示的单词作为预测词与true label的one-hot做比较，误差越小越好（根据误差更新权重矩阵）。</li>
</ol>
</blockquote>
<h3 id="训练Tricks"><a href="#训练Tricks" class="headerlink" title="训练Tricks"></a>训练Tricks</h3><p>Word2Vec本质上是一个语言模型，它的输出节点数是V个，对应了V个词语，本质上是一个多分类问题。但实际当中，词表数量巨大，计算复杂度巨高，所以需要技巧来加速训练。</p>
<blockquote>
<ul>
<li>层级softmax：本质是把N分类问题变成log(N)次的二分类；</li>
<li>负采样：本质是预测总体类别的一个子集</li>
</ul>
</blockquote>
<h4 id="负采样"><a href="#负采样" class="headerlink" title="负采样"></a>负采样</h4><p>在训练神经网络时，每个训练样本都将会调整所有神经网络中参数。词汇表决定了Word2Vec模型将会有非常大的权重矩阵，并且所有权重参数会随着数十亿训练昂呢不断调整。<br>负采样每次让一个训练样本更新一小部分的权重参数，从而降低梯度下降过程中的计算成本。  </p>
<p>负样本的选择规则：一个单词被选作负采样的概率与它出现的频次有关，出现频次越高的单词越容易被选择作为负样本，经验公式如下：<br><img src="/pictures/NLP/Word2Vec/img6.png.webp" alt="负采样概率"><br>f(w)代表每个单词被赋予的一个权重，即出现的词频。</p>
<h4 id="层序Softmax"><a href="#层序Softmax" class="headerlink" title="层序Softmax"></a>层序Softmax</h4><p>Huffman原理：权重越大的节点，越靠近根节点。</p>
<blockquote>
<ol>
<li>对每个词按照权重进行排序，将每次词看成一个独立的单节点的树；</li>
<li>合并最小的两个子树，新的根节点权重为两者根节点权重之和；</li>
<li>将新的树插入排序进树集合中；</li>
<li>重复2，3步骤，直到合并所有树。</li>
</ol>
</blockquote>
<h3 id="区别"><a href="#区别" class="headerlink" title="区别"></a>区别</h3><blockquote>
<p>cbow是用周围词预测中心词，训练过程中其实是在从output的loss学习周围词的信息也就是embedding，但是在中间层是average的，一共预测V次；<br>skip-gram是用中心词预测周围词，对每一个中心词都有K个词作为output，对一个词的预测有K次，所以能够更有效的从context中学习信息，共预测K*V次，因此，skip-gram的训练时间更长。</p>
</blockquote>
<p>鉴于skip-gram学习的词向量更细致，当 <strong>数据量较少或者语料库中有大量低频词</strong> 时，使用skip-gram学习比较合适。</p>
<blockquote>
<p>CBOW中的目标函数是使条件概率P(w|context(w))最大化<br>Skip-gram中的目标函数是使条件概率P(context(w)|w)最大化</p>
</blockquote>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/NLP/" rel="tag">NLP</a></li></ul>

    </footer>
  </div>

   
    
</article>

    
    <article
  id="post-AI/Normalization"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2022/09/25/AI/Normalization/"
    >Normalization</a> 
</h2>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2022/09/25/AI/Normalization/" class="article-date">
  <time datetime="2022-09-25T07:48:34.905Z" itemprop="datePublished">2022-09-25</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/">人工智能</a>
  </div>
   
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <p>机器学习领域有个很重要的假设：IID (Independent Identically Distribution) 独立同分布假设，即假设训练数据和测试数据是满足同分布的。</p>
<blockquote>
<p>神经网络的学习过程本质上是为了学习数据的分布。<br>在mini-batch梯度下降训练的时候，如果每批训练数据的分布不同，那么网络在每次迭代的时候都要学习适应不同的分布，大大降低了网络的训练速度。</p>
</blockquote>
<h2 id="BatchNorm"><a href="#BatchNorm" class="headerlink" title="BatchNorm"></a>BatchNorm</h2><p>BatchNorm就是在深度神经网络训练过程中，使得每一层神经网络的输入保持相同分布。</p>
<p>BN层在激活函数之前。BN层的作用机制：通过平滑隐藏层输入的分布，帮助随机梯度下降的进行，缓解随机梯度下降随遇后续层的负面影响。</p>
<blockquote>
<ol>
<li>sigmoid, tanh激活函数。函数图像两端，梯度较小，容易出现 <strong>梯度衰减</strong> 问题。因此，把BN层放在非线性激活函数之前，将数据分布调整到均值为0附近，加速训练。</li>
<li>relu激活函数。relu函数负半区的输出值被抑制，正半区的值被保留。因此，BN层放在前面，可以防止某一层的激活值全部被抑制，导致梯度全部为0，梯度消失。同理，防止梯度爆炸。</li>
</ol>
</blockquote>
<h3 id="Internal-Covariate-Shift-问题"><a href="#Internal-Covariate-Shift-问题" class="headerlink" title="Internal Covariate Shift 问题"></a>Internal Covariate Shift 问题</h3><p>在训练过程中，隐层的 <em><strong>输入分布</strong></em> 总是变来变去。导致下一层网络很难进行学习（神经网络本来就是要学习数据分布的）。</p>
<blockquote>
<p>Internal Covariate Shift: 发生在神经网络内部；<br>Covariate Shift: 发生在输入数据上。主要描述由于训练数据和测试数据存在分布差异，影响模型的泛化性和训练速度。</p>
</blockquote>
<h3 id="BatchNorm基本思想"><a href="#BatchNorm基本思想" class="headerlink" title="BatchNorm基本思想"></a>BatchNorm基本思想</h3><p>深度神经网络在做 <strong>非线性变化前</strong> 的激活输入值随着网络深度加深，在训练过程中，数据分布逐渐向着 <strong>非线性函数取值区间的上下限两端靠近</strong>，导致反向传播时，低层神经网络梯度消失，最终造成收敛变慢。</p>
<p>BN就是规范化隐层数据分布，将数据分布强制规范到非线形激活函数比较敏感的区域，避免梯度消失问题产生。<br>就是说经过BN后，大部分输出值落在非线形函数的非饱和区，加速收敛过程。</p>
<blockquote>
<p>如果都通过BN，那么不就跟把非线性函数替换成线性函数效果相同了？这意味着什么？我们知道，如果是多层的线性函数变换其实这个深层是没有意义的，因为多层线性网络跟一层线性网络是等价的。这意味着网络的表达能力下降了，这也意味着深度的意义就没有了。</p>
</blockquote>
<p>BN为了保证模型的非线形，对变换后的数据分布，进行了scale加上shift操作，<strong>这两个参数通过训练学习得到</strong>。等价于非线性函数的值，从正中心周围的线性区域往非线性区域偏移。增强模型的表达能力。</p>
<blockquote>
<p><strong>BN的核心思想：</strong>在非线性和线性之间找到较好的平衡点。既能享受非线性较强的表达能力，又能避免非线性激活函数饱和区梯度消失问题。</p>
</blockquote>
<h3 id="BatchNorm训练阶段"><a href="#BatchNorm训练阶段" class="headerlink" title="BatchNorm训练阶段"></a>BatchNorm训练阶段</h3><p>对于mini-batch SGD来说，一次训练过程中包含m个训练实例，其具体BN操作就是对于隐层中 <strong>每个神经元</strong> 的激活值，进行如下变换：<br><img src="/pictures/AI/Normal/img1.png" alt="每个神经元数据的标准化操作"></p>
<p>经过上述变化后，某个神经元的激活值变成了N(0, 1)正态分布。<br>为了防止网络表达能力下降，每个神经元增加两个调节参数，这两个参数通过训练学习得到，用来还原网络非线性表达能力。<br><img src="/pictures/AI/Normal/img2.png" alt="数据的放缩与偏移"></p>
<p>BN的具体操作流程如下，</p>
<blockquote>
<ol>
<li>先求出此次批量数据x的均值</li>
<li>求出此次batch的方差</li>
<li>接下来就是对x做归一化</li>
<li>最重要的一步，引入缩放和平移变量γ和β ,计算归一化后的值</li>
</ol>
</blockquote>
<p><img src="/pictures/AI/Normal/img3.png" alt="BN具体流程"></p>
<p>一个简单的代码实现，</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">def BatchNorm(x, gamma, beta, bn_param):</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">param:x		: 输入数据，shape(B, L)</span><br><span class="line">param:gamma	: 缩放因子</span><br><span class="line">param:beta	: 平移因子</span><br><span class="line">param:bn_param	: batchnorm所需要的一些参数</span><br><span class="line">	eps		: 接近0的数，防止分母出现0</span><br><span class="line">	momentum	: 动量参数，一般为0.9，0.99，0.999</span><br><span class="line">	running_mean	: 滑动平均的方式计算新的均值</span><br><span class="line">	running_var	: 滑动平均的方式计算新的方差</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">    x_mean = x.mean(axis=0)</span><br><span class="line">    x_var = x.var(axis=0)</span><br><span class="line">    x_norm = (x - x_mean) / np.sqrt(x_var + eps)</span><br><span class="line">    x_norm = gamma * x_norm + beta</span><br><span class="line"></span><br><span class="line">    # 滑动平均计算得到均值方差信息，用于推断阶段</span><br><span class="line">    running_mean = bn_param[&#x27;running_mean&#x27;]</span><br><span class="line">    running_var = bn_parma[&#x27;running_var&#x27;]</span><br><span class="line">    momentum = bn_param[&#x27;momentum&#x27;]</span><br><span class="line"></span><br><span class="line">    running_mean = momentum * running_mean + (1-momentum) * x_mean</span><br><span class="line">    running_var = momentum * running_var + (1-momentum) * x_var</span><br><span class="line"></span><br><span class="line">    bn_param[&#x27;running_mean&#x27;] = running_mean</span><br><span class="line">    bn_param[&#x27;running_var&#x27;] = running_var</span><br><span class="line"></span><br><span class="line">    return x_norm, bn_param</span><br></pre></td></tr></table></figure>

<p>在训练中完成的任务，每次训练给一个批量，然后计算批量的均值方差，但是在测试的时候可不是这样，测试的时候 <strong>每次只输入一张图片</strong>，这怎么计算批量的均值和方差，于是，就有了代码中下面两行，在训练的时候实现计算好mean和var，测试的时候直接拿来用就可以了，不用计算均值和方差。</p>
<h3 id="BatchNorm优势"><a href="#BatchNorm优势" class="headerlink" title="BatchNorm优势"></a>BatchNorm优势</h3><blockquote>
<ol>
<li>不仅仅极大提升了训练速度，收敛过程大大加快；</li>
<li>还能增加分类效果，一种解释是这是类似于Dropout的一种防止过拟合的正则化表达方式，所以不用Dropout也能达到相当的效果；</li>
<li>另外调参过程也简单多了，对于初始化要求没那么高，而且可以使用大的学习率等；</li>
<li>batchnorm降低了数据之间的绝对差异，有一个去相关的性质，更多的考虑相对差异性，因此在分类任务上具有更好的效果。</li>
</ol>
</blockquote>
<h2 id="Layer-Normalization"><a href="#Layer-Normalization" class="headerlink" title="Layer Normalization"></a>Layer Normalization</h2><h3 id="BatchNorm缺点"><a href="#BatchNorm缺点" class="headerlink" title="BatchNorm缺点"></a>BatchNorm缺点</h3><p>Batch size太小会影响模型性能。对batchsize的大小比较敏感，由于每次计算均值和方差是在一个batch上，所以 <strong>如果batchsize太小，则计算的均值、方差不足以代表整个数据分布</strong>；</p>
<p>BN实际使用时需要计算并且保存某一层神经网络batch的均值和方差等统计信息，对于对一个固定深度的前向神经网络（DNN，CNN）使用BN，很方便；但对于RNN来说，sequence的长度是不一致的，换句话说RNN的深度不是固定的，不同的time-step需要保存不同的statics特征，可能存在一个特殊sequence比其他sequence长很多，这样training时，计算很麻烦。</p>
<p>BN不适用于RNN等动态网络，适用于CNN；LN适用于RNN。</p>
<blockquote>
<p>很直观的一个例子：BN计算每个句子同一个位置字的均值和方差，但因为每个句子的长度不一样，最后是padding成一样的长度；那假如在该位置时，最后一句在该位置是没有字的，也就是用0表示了，那就会影响整个结果。</p>
</blockquote>
<h3 id="区别"><a href="#区别" class="headerlink" title="区别"></a>区别</h3><p>BN的主要思想：在每一层的每一批数据（一个batch里的同一个通道）上进行归一化；<br>LN的主要思想：在每一个样本（一个样本的不同通道）上计算均值和方差，并不是BN那种在批方向计算均值和方差。<br><img src="/pictures/AI/Normal/img4.png" alt="BN和LN的区别"></p>
<h3 id="源码实现"><a href="#源码实现" class="headerlink" title="源码实现"></a>源码实现</h3><p>Layer Normalization在NLP的直观图中，就是对一个batch中的同一句话中的 <strong>每个字</strong> 分别进行归一化。</p>
<p>如果只看 NLP 问题，假设我们的 batch 是（2,3,4）的，也就是 batch_size &#x3D; 2, seq_length &#x3D; 3, dim &#x3D; 4 的，假设第一个句子是 w1 w2 w3，第二个句子是 w4 w5 w6，那么这个 tensor 可以写为</p>
<blockquote>
<p>[ [[w11,w12,w13,w14], …]<br>[[w41,w42,w43,w44], …] ]</p>
</blockquote>
<p>如果是 BN 的话，会对同一个 batch 里对应位置上的 token 求平均值，也就是说 (w11+w12+w13+w14+w41+w42+w43+w44)&#x2F;8是其中一个 mean，一共会求出 3 个 mean，也就是上图里 C 个（seq_length）个 mean。</p>
<p>如果是 LN 的话，<strong>看起来（其实并不是）</strong> 是对每个 sample 里的所有 feature 求 mean，也就是(w11+w12+w13+w14+w21+w22+w23+w24+w31+w32+w33+w34)&#x2F;12，可以求出一共 2 个 mean，也就是图里 N（batch_size）个 mean。<br><img src="/pictures/AI/Normal/img5.png" alt="Layer Norm的不同"></p>
<p>左图和我们认为的 LN 一致，也是我一直认为的 LN，但是右图却是在一个 token 上求平均，带回我们原来的问题，对于一个(2,3,4)的 tensor，(w11+w12+w13+w14)&#x2F;4 是一个 mean，一共会有 2*3&#x3D;6 个 mean。</p>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/AI/" rel="tag">AI</a></li></ul>

    </footer>
  </div>

   
    
</article>

    
    <article
  id="post-RecomSys/MMoE"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2022/09/13/RecomSys/MMoE/"
    >MMoE</a> 
</h2>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2022/09/13/RecomSys/MMoE/" class="article-date">
  <time datetime="2022-09-13T09:53:23.838Z" itemprop="datePublished">2022-09-13</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/">推荐系统</a>
  </div>
   
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <p>在工业界基于神经网络的多任务学习在推荐等场景业务应用广泛，比如在推进啊系统中对用户推荐物品时，不仅要推荐用户感兴趣的物品，还要尽可能地促进转化和购买，因此要对用户评分和购买两种目标同时建模。</p>
<h3 id="动机"><a href="#动机" class="headerlink" title="动机"></a>动机</h3><p>把多个任务放在一起学习，任务共享同一个模型空间，它们 <strong>共享同一个表示层</strong>。在训练过程中，多个任务会对这个共享模型进行参数更新。</p>
<h4 id="相关任务"><a href="#相关任务" class="headerlink" title="相关任务"></a>相关任务</h4><p>multi task同时学习多个相关任务，并且具有相当的优势。同时，我们在做多任务学习时，有时关注的点在某个 <strong>主要任务</strong> 上，其他的共同学习的任务可能更多的只是起到帮助作用，这些起到帮助作用的任务叫做 <strong>辅助任务</strong>。</p>
<p><strong>辅助任务与主任务越相关，那么起到的效果可能会越好</strong>。<br>如下图所示，假如有这样两个相似的任务：狗的分类模型和猫的分类模型。在单任务学习中，他们都拥有比较接近的底层特征，比如皮毛颜色啦、眼睛颜色啦、耳朵形状啦等等。<br><img src="/pictures/RecomSys/MMoE/img1.png" alt="学习任务相近的单任务学习"></p>
<p>由于 <strong>多任务学习本质上是共享表示层</strong>，任务之间互相影响。那么在多任务学习中，他们就可以很好地进行底层特征共享。<br><img src="/pictures/RecomSys/MMoE/img2.png" alt="相关性较高的多任务学习"></p>
<p>但是对于不相似的任务来说，如下图，汽车的识别和狗的识别，他们的 <strong>底层表示差异很大</strong>，共享表示层可能就没那么有效果了。进行参数共享时很有可能会互相冲突或噪声太多，对多任务学习而言非常不友好。<br><img src="/pictures/RecomSys/MMoE/img3.png" alt="相关性较低的多任务学习"></p>
<blockquote>
<p>由于multi task在不相关的任务上表现不佳，同时，在实际应用中，你很难判断任务在数据层面是否是相似的。<br>所以多任务学习如何在相关性不高的任务上获得好效果是一件很有挑战性也很有实际意义的事。</p>
</blockquote>
<h4 id="共享表示"><a href="#共享表示" class="headerlink" title="共享表示"></a>共享表示</h4><p>神经网络中，Multi Task Learning的共享表示有两种方式：<strong>hard参数共享和soft参数共享</strong>。</p>
<h5 id="Hard参数共享"><a href="#Hard参数共享" class="headerlink" title="Hard参数共享"></a>Hard参数共享</h5><p>在所有任务之间 <strong>共享隐藏层</strong>，同时保留几个特定任务的输出层。这种方式很大程度上 <strong>降低了过拟合的风险</strong>。因为同时学习的工作越多，模型找到一个含有所有任务的表征就越困难，而过拟合某特定原始任务的可能性就越小。<br><img src="/pictures/RecomSys/MMoE/img4.png" alt="Hard参数共享"></p>
<h5 id="Soft参数共享"><a href="#Soft参数共享" class="headerlink" title="Soft参数共享"></a>Soft参数共享</h5><p>每个任务有自己的参数和模型，最后 <strong>通过对不同任务的参数之间的差异加约束</strong>，表达相似性。比如可以使用L2进行正则, 迹范数（trace norm）等。<br><img src="/pictures/RecomSys/MMoE/img5.png" alt="Soft参数共享"></p>
<h4 id="多任务学习优势"><a href="#多任务学习优势" class="headerlink" title="多任务学习优势"></a>多任务学习优势</h4><ol>
<li>多个任务一起学习时，<strong>有相关部分也有不那么相关的地方</strong>，在学习一个任务时，与它不相关的部分就相当于是加入一些噪声，而 <strong>加入噪声可以提升模型的泛化能力</strong>。</li>
<li>单任务学习时容易陷入局部最优，而多任务学习中 <strong>不同任务的局部最优解处于不同的位置</strong>，通过相互作用，可以逃离局部最优。</li>
<li>增加任务会影响网络参数的更新，比如增加额外的任务增加了隐层的有效的学习率，具体取决于每个任务输出的错误反馈权重。可能较大的学习速率提升了学习效果</li>
<li>某些特征可能在主任务不好学习（比如以很复杂的方式与特征进行交互，或被其他因素抑制），但在辅助任务上这个特征好学习到。可以通过辅助任务来学习这些特征，方法比如hints（预测重要特征）</li>
<li>通过学习足够大的假设空间，在未来某些新任务中可以有较好的表现（解决冷启动），前提是这些任务都是 <strong>同源</strong> 的。</li>
<li>多个任务在浅层共享表示，引入归纳偏置作为正则化项。因此，它降低了过拟合的风险以及模型的 Rademacher 复杂度（即适合随机噪声的能力）</li>
</ol>
<h3 id="MMoE模型结构"><a href="#MMoE模型结构" class="headerlink" title="MMoE模型结构"></a>MMoE模型结构</h3><p>关于共享隐层方面，MMoE和一般多任务学习模型的区别：</p>
<blockquote>
<p><strong>一般多任务学习模型</strong>：接近输入层的隐层作为一个整体被共享；<br><strong>MMoE</strong>：将共享的底层表示层分为 <strong>多个expert</strong>，同时设置了gate，使得 <strong>不同的任务可以多样化的使用共享层</strong>。</p>
</blockquote>
<p><img src="/pictures/RecomSys/MMoE/img6.png" alt="网络结构变化"></p>
<blockquote>
<p>a）是最原始的多任务学习模型，也就是base；<br>b）是加入单门（one gate）的MoE layer的多任务学习模型；<br>c）本质上是将base的shared bottom换成了MoE layer，并对每个任务都加gate</p>
</blockquote>
<h4 id="Mixture-of-Expert-Model"><a href="#Mixture-of-Expert-Model" class="headerlink" title="Mixture-of-Expert Model"></a>Mixture-of-Expert Model</h4><p>隐层是三个expert子网组成，各自的输出 f[i]（第 i 个expert的输出）会传入gate，也就是 g(x) 维度与expert个数相同的 <strong>softmax</strong>，g(x)[i] 是它输出的第 i 个logits。<strong>gate对expert的输出进行加权求和，得到不同任务的输入</strong>。<br><img src="/pictures/RecomSys/MMoE/img10.png" alt="MoE模型计算公式"></p>
<h4 id="Shared-Bootom-Model"><a href="#Shared-Bootom-Model" class="headerlink" title="Shared-Bootom Model"></a>Shared-Bootom Model</h4><p>模型 (a) 最为常见，两个任务直接共享模型的 bottom 部分，只在最后处理时做区分，图 (a) 中使用了 Tower A 和 Tower B，然后分别接损失函数。<br><img src="/pictures/RecomSys/MMoE/img7.png" alt="Base模型"><br>x 表示 input，f 表示 shared-bottom network， h[k] 表示第 k 个tower network，针对第k个任务。</p>
<p>这种网络非常简单，可以理解为在DNN上接了 k 个不同的tower 网络，不同的tower网络针对不同任务，有着各自的损失函数，但是 <strong>这些损失函数是放在一起进行联合训练</strong>。</p>
<p>直觉告诉我们，如此进行多任务学习，在某些情况下效果可能并不好，例如当多个任务间是矛盾的，或者完全不相关的。</p>
<h4 id="One-gate-MoE-Model"><a href="#One-gate-MoE-Model" class="headerlink" title="One-gate MoE Model"></a>One-gate MoE Model</h4><p>模型 (b) 是常见的多任务学习模型。将 input 分别输入给三个 Expert，但 <strong>三个Expert并不共享参数</strong>。同时将 input 输出给 Gate，<strong>Gate输出每个Expert被选择的概率</strong>，然后将三个Expert的输出 <strong>加权求和</strong>，输出给 Tower。有点 attention 的感觉。<br><img src="/pictures/RecomSys/MMoE/img8.png" alt="OMoE模型公式"><br>上式中，n 表示有 n 个 expert networks，f<a href="x">i</a> 表示第 i 个expert network，在论文expert network就是DNN网络。g(x)[i] 是由 输入x 控制的，其中 W[g] ∈ R[n × d]，n 表示expert network数量，d表示输入x 的特征维度，在n维度上进行softmax，因此 g(x)[i] 可理解为 <strong>通过输入x 得到在n个 exper network 上的权重分布</strong>。同样，h[k] 表示第k个 tower network。</p>
<p>这个网络也很简单，可以理解为 对多个不同 expert network进行不同权重的集成，在集成的结果上接不同的tower network 而已。模型在训练过程中，会学习到不同expert network重要程度。</p>
<p>那么何为 One-gate 呢？ 从上面的分析可以看出，不同的tower network的输入是相同的，都是经过同一套权重组合（同一个gate network）得到expert networks的输出。这么这样做合理吗？</p>
<h4 id="Multi-gate-MoE-Model"><a href="#Multi-gate-MoE-Model" class="headerlink" title="Multi-gate MoE Model"></a>Multi-gate MoE Model</h4><p>模型 (c) 是作者新提出的方法，对于不同的任务，模型的权重选择是不同的，所以作者为每个任务都配备一个 Gate 模型。<strong>对于不同的任务，特定的 Gate k 的输出表示不同的 Expert 被选择的概率</strong>，将多个 Expert 加权求和，得到 f<a href="x">k</a> ，并输出给特定的 Tower 模型，用于最终的输出。<br><img src="/pictures/RecomSys/MMoE/img9.png" alt="MMoE模型公式"><br>与OMoE区别仅在 对于不同的tower network，有着不同的gate network，在OMoE上，只会初始化一个W[g] 参数矩阵，而在MMoE上，会初始化 k 个 W[gk]，得到 k 个gate network（multi-gates&#x2F;task-specific gates)，参数增加了一些。</p>
<p>相对于OMoE，MMoE的做法更加合理一些，不同的任务有着不同的gate network，对expert networks输出有着不同权重组合。</p>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Recom/" rel="tag">Recom</a></li></ul>

    </footer>
  </div>

   
    
</article>

    
    <article
  id="post-RecomSys/DIN"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2022/09/13/RecomSys/DIN/"
    >DIN</a> 
</h2>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2022/09/13/RecomSys/DIN/" class="article-date">
  <time datetime="2022-09-13T02:56:45.257Z" itemprop="datePublished">2022-09-13</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/">推荐系统</a>
  </div>
   
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>针对电子商务领域的CTR预估，重点在与充分利用&#x2F;挖掘用户历史行为数据中的信息。</p>
<blockquote>
<p>按照传统方式，模型在预估针对用户推荐的广告时，对于 <em><strong>所有用户的特征选取总是使用固定长度</strong></em>。这样带来的问题就是，<em><strong>推荐系统并不能准确的把握用户的兴趣所在</strong></em>。</p>
</blockquote>
<h4 id="Attention机制引入"><a href="#Attention机制引入" class="headerlink" title="Attention机制引入"></a>Attention机制引入</h4><p>并不是所有的用户历史行为数据，对每一次的点击有贡献，而 <em><strong>仅仅有一部分在起作用</strong></em>。这个性质有些像attention，对于当前状态的预估，需要告知模型，哪些点与当前的预估最相关；</p>
<p>在对用户历史行为数据进行处理时，每个用户的历史点击个数是不相等的，我们需要把它们编码成一个固定长的向量。以往的做法是，对每次历史点击做相同的embedding操作之后，将它们做一个 <em><strong>求和或者求最大值</strong></em> 的操作，类似经过了一个pooling层操作，简单粗暴，但是容易丢失很多信息。</p>
<h4 id="模型改进"><a href="#模型改进" class="headerlink" title="模型改进"></a>模型改进</h4><blockquote>
<ul>
<li>使用 <strong>用户兴趣分布</strong> 来表示用户多种多样的兴趣爱好；</li>
<li>使用 <strong>attention机制</strong> 来实现Local Activation；</li>
<li>针对模型训练，提出了 <strong>Dice激活函数，自适应正则</strong>，显著提升了模型性能与收敛速度。</li>
</ul>
</blockquote>
<h4 id="名词解释"><a href="#名词解释" class="headerlink" title="名词解释"></a>名词解释</h4><h5 id="Diversity-多样性"><a href="#Diversity-多样性" class="headerlink" title="Diversity 多样性"></a>Diversity 多样性</h5><p>用户在访问电商网站时会对多种商品感兴趣，也就是用户的兴趣非常广泛。<br>针对用户广泛的兴趣，DIN用 an interest distribution 去表示。</p>
<h5 id="Local-Activation-局部激活"><a href="#Local-Activation-局部激活" class="headerlink" title="Local Activation 局部激活"></a>Local Activation 局部激活</h5><p>用户是否会点击推荐给他的商品 ，仅仅取决与历史行为数据的一小部分，而不是全部。</p>
<p>DIN借鉴机器翻译中的Attention机制，设计了一种 <strong>attention-like network structure</strong>， 针对当前候选Ad，去局部的激活(Local Activate)相关的历史兴趣信息。<strong>和当前候选Ad相关性越高的历史行为，会获得更高的attention score，从而会主导这一次预测</strong>。</p>
<h4 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h4><p>DIN方法也可以应用于其他有丰富用户行为数据的场景，比如：</p>
<blockquote>
<ul>
<li>电子商务中的个性化推荐；</li>
<li>社交网络中的信息推流排序(feeds ranking)</li>
</ul>
</blockquote>
<h3 id="系统构建"><a href="#系统构建" class="headerlink" title="系统构建"></a>系统构建</h3><p>阿里推荐系统工作流程：</p>
<blockquote>
<ol>
<li>检查用户历史行为数据；</li>
<li>使用 matching module 产生 候选ads；</li>
<li>通过 ranking module 得到 候选ads 的点击概率，并根据概率排序得到推荐列表；</li>
<li>记录下用户对当前展示广告的反应（点击与否）</li>
</ol>
</blockquote>
<p>这是一个闭环系统，对于用户行为数据（User Behavior Data），系统自己生产并自己消费。</p>
<h3 id="训练数据"><a href="#训练数据" class="headerlink" title="训练数据"></a>训练数据</h3><p>数据有以下特点：</p>
<blockquote>
<ul>
<li>Diversity – 兴趣爱好非常广泛；</li>
<li>Local Activation – 历史行为中部分数据主导是否会点击候选广告；</li>
<li>高纬度；</li>
<li>非常稀疏；</li>
<li>特征往往都是 multi-hot 的稀疏ids。</li>
</ul>
</blockquote>
<p><img src="/pictures/RecomSys/DIN/img1.png" alt="特征数据"></p>
<h4 id="特征处理"><a href="#特征处理" class="headerlink" title="特征处理"></a>特征处理</h4><p>论文中作者把特征分为四大类，并 <strong>没有进行特征组合&#x2F;交叉特征</strong>。而是 <strong>通过 DNN 去学习特征间的交互信息</strong>。</p>
<blockquote>
<ul>
<li>User Profile Features</li>
<li>User Behavior Features</li>
<li>Ad Features</li>
<li>Context Features</li>
</ul>
</blockquote>
<p>为了得到一个 <strong>固定长度</strong> 的 Embedding Vector 表示，原来的做法是在 Embedding Layer 后面 <strong>增加一个 Pooling Layer</strong>。Pooling可以用 sum 或 average。最终得到一个固定长度的 Embedding Vector，是用户兴趣的一个抽象表示，常被称作 User Representation。缺点是会损失一些信息。<br><img src="/pictures/RecomSys/DIN/img2.png" alt="传统模型"></p>
<p>DIN使用 Attention机制 来解决这个问题。Attention机制 来源于 Neural Machine Translation(NMT)。DIN使用 Attention机制 去更好的建模 局部激活。在DIN场景中，针对不同的候选广告需要自适应地调整 User Representation。也就是说：在 Embedding Layer -&gt; Pooling Layer 得到用户兴趣表示的时候，赋予不同的历史行为不同的权重，实现局部激活。从最终反向训练的角度来看，就是根据当前的候选广告，来反向的激活用户历史的兴趣爱好，赋予不同历史行为不同的权重。<br><img src="/pictures/RecomSys/DIN/img3.png" alt="DIN模型结构"></p>
<h3 id="模型训练"><a href="#模型训练" class="headerlink" title="模型训练"></a>模型训练</h3><h4 id="评价指标-GAUC"><a href="#评价指标-GAUC" class="headerlink" title="评价指标 GAUC"></a>评价指标 GAUC</h4><p>不同于以往CTR模型采用AUC作为评价指标，论文采用的评价指标是自己设计的 GAUC 评价指标。</p>
<p><em><strong>AUC的含义是正样本得分比负样本得分高的概率</strong></em>。在CTR的实际应用场景中，CTR预测常被应用于对每个用户的候选广告进行排序，也即最终想得到的效果是 <em><strong>每个用户的AUC达到最高</strong></em>。同时，<strong>不同用户的AUC之间也确实存在差别，有的用户天生点击率就高，有的用户却不怎么喜欢点击广告</strong>。</p>
<p>以往的评价指标是对样本不区分用户地进行AUC计算。论文采用的GAUC计算了 <strong>用户级别的AUC</strong>，在单个用户AUC的基础上，按照 <strong>点击次数或展示次数进行加权平均</strong>，消除了用户偏差对模型的影响，更准确地描述了模型对于每个用户的表现效果。<br><img src="/pictures/RecomSys/DIN/img4.png" alt="GAUC计算公式"><br>w 可以是 <strong>clicks（点击次数） 或者 impressions（展示次数）</strong>，n 是用户数量。这中AUC也应该是在 <strong>个性化推荐</strong> 里面更适合的，用户每个个体都有自己的AUC。</p>
<h4 id="激活函数-Dice"><a href="#激活函数-Dice" class="headerlink" title="激活函数 Dice"></a>激活函数 Dice</h4><p>Dice其实是ReLU的改良版，ReLU可以看作是 x * Max(x, 0)，相当于输出 x  经过了一个在0点的阶跃整流器。由于ReLU在 x&lt;0 的时候，梯度为0，可能导致网络停止更新，PReLU对整流器的左半部分形式进行了修改，使得 x&lt;0 时输出不为0。<br><img src="/pictures/RecomSys/DIN/img5.png" alt="激活函数"></p>
<p>论文里认为，对于所有输入不应该都选择0点为整流点。于是提出了一种data dependent的方法，并称该激活函数为Dice函数。<br><img src="/pictures/RecomSys/DIN/img6.png" alt="Dice激活函数"><br>概率值 p[i] 决定输出是取 y[i] 或者是 a[i] * y[i]，p[i] 也起到了整流器的作用。<br>获取 p[i] 的两步操作：</p>
<blockquote>
<ol>
<li>对 x 进行均值归一化处理。使得整流点是在数据的均值处，实现data dependent的想法；</li>
<li>经过一个 sigmoid函数的计算，得到一个0到1的概率值。</li>
</ol>
</blockquote>
<h4 id="自适应正则"><a href="#自适应正则" class="headerlink" title="自适应正则"></a>自适应正则</h4><p>在CTR预估任务中，用户行为数据具有长尾分布的特点，也即数据非常的稀疏。</p>
<p>稀疏输入，为什么会overfitting呢？这个跟数据分布有关系，互联网时代的数据特点，<em><strong>超长尾头部重，头重（小比例的特征频繁出现）容易过拟合，长尾（大比例的特征低频出现）则容易带来噪声</strong></em>，不好学。当增加细粒度的特征时，也极其容易由于细粒度的样本过于密集而带来负面效果。</p>
<p>为了防止模型过拟合，论文设计了一个针对 <strong>feature id出现的频率</strong> 进行自适应的正则方法。</p>
<blockquote>
<ul>
<li>针对feature id出现的频率，来自适应的调整他们正则化的强度；</li>
<li>对于出现频率高的，给与较小的正则化强度；</li>
<li>对于出现频率低的，给予较大的正则化强度。</li>
</ul>
</blockquote>
<h3 id="模型结构"><a href="#模型结构" class="headerlink" title="模型结构"></a>模型结构</h3><p>传统深度模型<br><img src="/pictures/RecomSys/DIN/img7.png" alt="传统深度模型"></p>
<p>DIN模型在对用户的表示计算上引入了attention network (也即图中的 Activation Unit ) 。<br><img src="/pictures/RecomSys/DIN/img8.png" alt="DIN模型结构"></p>
<p>DIN把用户特征、用户历史行为特征进行embedding操作，视为对用户兴趣的表示，之后通过attention network，<em><strong>对每个兴趣表示赋予不同的权值</strong></em>。这个权值是由用户的兴趣和待估算的广告进行匹配计算得到的，如此模型结构符合了之前的两个观察——用户兴趣的多样性以及部分对应。attention network 的计算公式如下， V_u 代表用户表示向量， V_i 代表用户兴趣表示向量， V_a 代表广告表示向量。<br><img src="/pictures/RecomSys/DIN/img9.png" alt="attention机制"></p>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Recom/" rel="tag">Recom</a></li></ul>

    </footer>
  </div>

   
    
</article>

    
    <article
  id="post-RecomSys/DeepFM"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2022/09/12/RecomSys/DeepFM/"
    >DeepFM</a> 
</h2>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2022/09/12/RecomSys/DeepFM/" class="article-date">
  <time datetime="2022-09-12T08:37:32.994Z" itemprop="datePublished">2022-09-12</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/">推荐系统</a>
  </div>
   
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><h4 id="特征组合的挑战"><a href="#特征组合的挑战" class="headerlink" title="特征组合的挑战"></a>特征组合的挑战</h4><p>对于基于CTR预估的推荐系统，最重要的是学习到用户点击行为背后隐含的特征组合。在不同的推荐场景中，低阶组合特征或者高阶组合特征可能会对最终的CTR产生影响。</p>
<p>因子分解机通过对于每一维特征的隐变量的内积来提取特征组合。理论上FM可以对高阶特征组合进行建模，但是实际上因为计算复杂度的原因，一般只用到了二阶特征组合。对于高阶特征组合，使用多层神经网络DNN解决。</p>
<h4 id="DNN的局限性"><a href="#DNN的局限性" class="headerlink" title="DNN的局限性"></a>DNN的局限性</h4><p>对于离散特征的处理，使用one-hot编码。但是将one-hot编码直接输入到DNN中，会导致网络参数过多。<br><img src="/pictures/RecomSys/DeepFM/img1.png" alt="one-hot编码不可以直接输入DNN"></p>
<p>采用类似于FFM中的思想，将特征分为不同的field。<br><img src="/pictures/RecomSys/DeepFM/img2.png" alt="Embedding生成"></p>
<p>再加两层全连接层，便可以组合出高阶特征。<br><img src="/pictures/RecomSys/DeepFM/img3.png" alt="高阶特征组合"></p>
<p>但是低阶和高阶特征组合隐含地体现在隐藏层中，如果我们希望把低阶特征组合单独建模，然后融合高阶特征组合。<br><img src="/pictures/RecomSys/DeepFM/img4.png" alt="并行结构 DeepFM"></p>
<p><img src="/pictures/RecomSys/DeepFM/img5.png" alt="串行结构 FNN"></p>
<p>目前的CTR预估模型，实质上都是在“利用模型”进行特征工程上狠下功夫。传统的LR，简单易解释，但特征之间信息的挖掘需要大量的人工特征工程来完成。由于深度学习的出现，利用神经网络本身对于隐含特征关系的挖掘能力，成为了一个可行的方式。<em><strong>DNN本身主要是针对于高阶的隐含特征</strong></em>，而像FNN（利用FM做预训练实现embedding，再通过DNN进行训练，有时间会写写对该模型的认识）这样的模型则是考虑了高阶特征，而在最后sigmoid输出时 <em><strong>忽略了低阶特征本身</strong></em>。</p>
<p>鉴于上述理论，目前新出的很多基于深度学习的CTR模型都从wide、deep（即低阶、高阶）两方面同时进行考虑，进一步提高模型的泛化能力，比如DeepFM。</p>
<h3 id="模型结构"><a href="#模型结构" class="headerlink" title="模型结构"></a>模型结构</h3><p>DeepFM包含两个部分：神经网络部分与因子分解机部分，分别负责低阶特征的提取和高阶特征的提取。这两个部分 <em><strong>共享同样的输入</strong></em>。<br><img src="/pictures/RecomSys/DeepFM/img6.png" alt="DeepFM网络结构"></p>
<h4 id="FM部分"><a href="#FM部分" class="headerlink" title="FM部分"></a>FM部分</h4><p><img src="/pictures/RecomSys/DeepFM/img7.png" alt="FM模块结构"><br>传统度量特征 i 和 j 权重的方法，<strong>需要两者同时存在于同一条数据记录中</strong>。<br>FM部分是一个因子分解机。因为FM中引入 <strong>隐变量</strong> 的原因，对于几乎不出现或者很少出现的隐变量，FM也可以很好的学习。</p>
<p>FM通过两个特征的隐向量的内乘积进行表示。不需要同时存在于同一条记录中。<br><img src="/pictures/RecomSys/DeepFM/img8.png" alt="因子分解"></p>
<p>FM的输出为：<br><img src="/pictures/RecomSys/DeepFM/img9.png" alt="FM模型公式"></p>
<h4 id="Deep部分"><a href="#Deep部分" class="headerlink" title="Deep部分"></a>Deep部分</h4><p><img src="/pictures/RecomSys/DeepFM/img10.png" alt="DNN模块结构"><br>Deep部分是一个前馈神经网络。与图像或者语音这类输入不同，图像语音的输入一般是连续并且密集的，然而用于CTR的输入一般是及其稀疏的。因此，在第一层隐藏层之前，<strong>引入一个嵌入层来完成将输入向量压缩到低维稠密向量</strong>。</p>
<h4 id="Embedding层"><a href="#Embedding层" class="headerlink" title="Embedding层"></a>Embedding层</h4><p><img src="/pictures/RecomSys/DeepFM/img11.png" alt="Embedding层网络结构"><br>嵌入层(embedding layer)的结构如上图所示。当前网络结构有两个有趣的特性<br>尽管不同field的输入长度不同，但是embedding之后向量的长度均为K；<br>在FM里得到的隐变量 V_ik 现在作为了嵌入层网络的权重。</p>
<p>这里的第二点如何理解呢，假设我们的 k&#x3D;5，首先，对于输入的一条记录，<em><strong>同一个field 只有一个位置是1</strong></em>，那么在由输入得到dense vector的过程中，输入层只有一个神经元起作用，得到的dense vector其实就是 <em><strong>输入层到embedding层该神经元相连的五条线的权重</strong></em>，即v_i1，v_i2，v_i3，v_i4，v_i5。这五个值组合起来就是我们在FM中所提到的V_i。</p>
<p>在FM部分和DNN部分，这一块是 <em><strong>共享权重</strong></em> 的，对同一个特征来说，得到的V_i是相同的。</p>
<h4 id="输出层"><a href="#输出层" class="headerlink" title="输出层"></a>输出层</h4><p>DeepFM的预测结果为：<br><img src="/pictures/RecomSys/DeepFM/img12.png" alt="输出层计算"></p>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Recom/" rel="tag">Recom</a></li></ul>

    </footer>
  </div>

   
    
</article>

    
    <article
  id="post-RecomSys/Wide-and-Deep"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2022/09/12/RecomSys/Wide-and-Deep/"
    >Wide&amp;Deep</a> 
</h2>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2022/09/12/RecomSys/Wide-and-Deep/" class="article-date">
  <time datetime="2022-09-12T07:05:58.169Z" itemprop="datePublished">2022-09-12</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/">推荐系统</a>
  </div>
   
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>推荐系统的主要挑战之一，是同时解决 Memorization 和 Generalization。Wide&amp;Deep模型旨在使得训练得到的模型能够同时获得记忆和泛化能力。</p>
<blockquote>
<p><strong>Memorization</strong>: 根据历史行为数据，产生的推荐通常和用户已有行为的物品直接相关的物品；<br><strong>Generalization</strong>: 会学习新的特征组合，提高推荐物品的多样性。</p>
</blockquote>
<h4 id="记忆能力"><a href="#记忆能力" class="headerlink" title="记忆能力"></a>记忆能力</h4><p>面对拥有大规模离散sparse特征的CTR预估问题，将特征进行非线性转换，然后再使用线性模型是业界非常普遍的做法，最流行的即 <em><strong>LR+特征叉乘</strong></em>。Memorization 通过一系列人工的特征叉乘来构造这些非线性特征，捕捉 sparse 特征之间的高阶相关性，即 <em><strong>“记忆”历史数据中曾经共同出现过的特征对</strong></em>。</p>
<p>典型代表是LR模型，使用大量的原始sparse特征和叉乘特征作为输入，很多原始的dense特征通常会被分桶离散化为sparse特征。</p>
<p>这种做法的优点是：</p>
<blockquote>
<p>模型可解释性高，实现快速高效，特征重要度易于分析。</p>
</blockquote>
<p>缺点是：</p>
<blockquote>
<ol>
<li>需要更多的人工设计；</li>
<li>可能出现过拟合。可以理解为，如果将所有特征叉乘起来，那么几乎相当于纯粹记住每个训练样本，这个极端情况是最细粒度的叉乘，我们可以通过构建更粗粒度的特征叉乘来增强泛化性；</li>
<li>无法捕捉训练数据集中未曾出现过的特征对；</li>
</ol>
</blockquote>
<h4 id="泛化能力"><a href="#泛化能力" class="headerlink" title="泛化能力"></a>泛化能力</h4><p>Generalization 为 sparse 特征学习低维的 dense embedding 来捕捉特征相关性，学习到的embeddings 本身带有一定的语义信息。可以联想到 NLP 的词向量，不同词的词向量有相关性，因此文中也称 Generalization 是基于相关性之间的传递。这类模型的代表是 DNN 和 FM。</p>
<p>Generalization 的优点是更少的人工参与，对历史上没有出现的特征组合有更好的泛化性。但是在推荐系统中，当 user-item matrix 非常稀疏，NN很难为 users 和 items 学习到有效的 embedding。这种情况下，大部分 user-item 应该是没有关联的，但 dense embedding 的方法还是可以得到对所有 user-item pair 的非零预测，因此导致 over-generalize 并推荐不怎么相关的物品。此时 Memorization 就展示了优势，它可以记住这些特殊的特征组合。</p>
<h3 id="模型结构"><a href="#模型结构" class="headerlink" title="模型结构"></a>模型结构</h3><p>Wide&amp;Deep 模型结合了 LR 和 DNN，其框架图如下所示：<br><img src="/pictures/RecomSys/Wide-and-Deep/img1.png" alt="网络结构"></p>
<h4 id="Wide部分"><a href="#Wide部分" class="headerlink" title="Wide部分"></a>Wide部分</h4><p>该部分是广义线性模型</p>
<blockquote>
<p>y &#x3D; W * [x, f(x)] + b<br>其中，x 和 f(x) 分别表示 <em><strong>原始特征和交叉特征</strong></em>。</p>
</blockquote>
<h4 id="Deep部分"><a href="#Deep部分" class="headerlink" title="Deep部分"></a>Deep部分</h4><p>该部分是前馈神经网络，网络会对一些sparse特征学习一个低维的dense embedding（维度量级通常在O(10)到O(100)之间），然后和一些原始 dense 特征一起作为网络的输入。</p>
<p>每一层隐层计算为：<br><img src="/pictures/RecomSys/Wide-and-Deep/img2.png" alt="隐层计算公式"></p>
<h4 id="输出层"><a href="#输出层" class="headerlink" title="输出层"></a>输出层</h4><p>模型选取 logistic loss 作为损失函数，此时 Wide&amp;Deep 最后的预测输出为：<br><img src="/pictures/RecomSys/Wide-and-Deep/img3.png" alt="输出层计算"></p>
<h3 id="联合训练"><a href="#联合训练" class="headerlink" title="联合训练"></a>联合训练</h3><p>联合训练（Joint Training）和集成（Ensemble）是不同的。<br>集成是每个模型单独训练，再将模型的结果汇合。相比于联合训练，集成的每个独立模型都得学的足够好才有利于随后的汇合，因此每个 model size 相对更大。<br>而联合学习的wide部分只需要做一小部分的特征叉乘来弥补deep部分的不足，不需要一个 full-size 的wide模型。</p>
<p>在论文中，作者通过梯度的反向传播，使用 mini-batch stochastic optimization 训练参数，并对 wide 部分使用带 L1正则的 Follow-the-regularized-leader(FTRL)算法，对 deep 部分使用 AdaGrad 算法。</p>
<h3 id="场景应用"><a href="#场景应用" class="headerlink" title="场景应用"></a>场景应用</h3><h4 id="应用背景"><a href="#应用背景" class="headerlink" title="应用背景"></a>应用背景</h4><p>Google Play 商店的 app 推荐中，当一个 user 访问 Google Play，会生成一个包含 user 和 contextual 信息的 query，推荐系统的精排模型会对于候选池中召回的一系列 app（即 item，文中也称 impression）进行打分，按打分生成 app 的排列列表返回给用户。Deep&amp;Wide 对应这里的精排模型，输入 x 包括 &lt;user, contextual, impression&gt;的信息，y &#x3D; 1表示用户下载了 impression app，打分即为 p(y|x)。</p>
<p>实验的Deep &amp; Wide模型结构如下：<br><img src="/pictures/RecomSys/Wide-and-Deep/img4.png" alt="网络结构"></p>
<h4 id="实验细节"><a href="#实验细节" class="headerlink" title="实验细节"></a>实验细节</h4><blockquote>
<ul>
<li>训练样本约5000亿</li>
<li>Categorical 特征（sparse）会有一个过滤阈值，即至少在训练集中出现m次才会被加入</li>
<li>Continuous 特征（dense）通过CDF被归一化到 [0,1] 之间</li>
<li>Categorical 特征映射到32维embeddings，和原始Continuous特征共1200维作为NN输入</li>
<li>Wide部分只用了一组特征叉乘，即被推荐的app ☓ 用户下载的app</li>
<li>线上模型更新时，通过“热启动”重训练，即使用上次的embeddings和模型参数初始化</li>
</ul>
</blockquote>
<p>Wide部分设置很有意思，作者为什么这么做呢？<br>结合业务思考，在Google Play商店的app下载中，不断有新的app推出，并且有很多“非常冷门、小众”的app，而现在的智能手机user几乎全部会安装一系列必要的app。</p>
<p>联想前面对Memorization和Generalization的介绍，此时的Deep部分无法很好的为这些app学到有效的embeddding，而这时Wide可以发挥了它“记忆”的优势，作者在这里选择了 <em><strong>“记忆”user下载的app与被推荐的app之间的相关性</strong></em>，有点类似“装个这个app后还可能会装什么”。</p>
<p>对于Wide来说，它现在的任务是弥补Deep的缺陷，其他大部分的活就交给Deep了，所以这时的Wide相比单独Wide也显得非常“轻量级”，这也是Join相对于Ensemble的优势。</p>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Recom/" rel="tag">Recom</a></li></ul>

    </footer>
  </div>

   
    
</article>

    
    <article
  id="post-RecomSys/FM"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2022/09/12/RecomSys/FM/"
    >FM</a> 
</h2>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2022/09/12/RecomSys/FM/" class="article-date">
  <time datetime="2022-09-12T03:45:34.425Z" itemprop="datePublished">2022-09-12</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/">推荐系统</a>
  </div>
   
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <h3 id="FM"><a href="#FM" class="headerlink" title="FM"></a>FM</h3><h4 id="提出背景"><a href="#提出背景" class="headerlink" title="提出背景"></a>提出背景</h4><p>传统线性模型忽略了特征之间的交叉联系；特征高维稀疏，并且容易维度爆炸。</p>
<p>FM就是Factor Machine，因子分解机。<br>FM通过对两两特征组合，引入交叉项特征，提高模型得分；其次是高维灾难，通过引入隐向量（对参数矩阵进行矩阵分解），完成对特征的参数估计。</p>
<h4 id="模型公式"><a href="#模型公式" class="headerlink" title="模型公式"></a>模型公式</h4><p><strong>一般的线性模型</strong><br><img src="/pictures/RecomSys/FM/img1.png" alt="一般线性模型"></p>
<p><strong>二阶多项式模型</strong><br><img src="/pictures/RecomSys/FM/img2.png" alt="二阶多项式模型"><br>上式中，n表示样本的特征数量，x[i]表示第i个特征。<br>与线性模型相比，FM模型多了后面特征组合的部分。</p>
<h4 id="FM求解"><a href="#FM求解" class="headerlink" title="FM求解"></a>FM求解</h4><p>从上面的式子可以看到，组合部分的特征相关参数有 n(n−1)&#x2F;2 个。但是对于稀疏数据来说，同时满足 x i , x[i], x[j] 都不为0的情况十分少，这就会导致 w[i][j] 无法通过训练得到。</p>
<p>为了求解得到w[i][j]，我们对于每一个特征分量 x[i] 引入 <strong>隐向量</strong> V[i] &#x3D; (v[i][1], …, v[i][k])，利用v[i]，v[j]对w[i][j]进行求解。<br><img src="/pictures/RecomSys/FM/img3.png" alt="权重矩阵W求解"></p>
<p>求解v[i]和v[j]的具体过程如下：<br><img src="/pictures/RecomSys/FM/img4.png" alt="核心计算公式"></p>
<h3 id="FFM"><a href="#FFM" class="headerlink" title="FFM"></a>FFM</h3><h4 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h4><p>同一个categorical特征经过One-Hot编码生成的数值特征都可以放到同一个field，包括用户性别、职业、品类偏好等。</p>
<p>在FFM中，每一维特征 x[i]，针对其它特征的每一种field f[j]，都会学习一个隐向量 v[i][f]。因此，<em><strong>隐向量不仅与特征相关，也与field相关</strong></em>。也就是说，“Day&#x3D;26&#x2F;11&#x2F;15”这个特征与“Country”特征和“Ad_type”特征进行关联的时候使用不同的隐向量，这与“Country”和“Ad_type”的内在差异相符，也是FFM中“field-aware”的由来。</p>
<p>假设样本的 n 个特征属于 f 个field，那么FFM的二次项有 nf个隐向量。而在FM模型中，每一维特征的隐向量只有一个，即二次项有n个隐向量。FM可以看作FFM的特例，是把所有特征都归属到一个field时的FFM模型。根据FFM的field敏感特性，可以导出其模型方程。<br><img src="/pictures/RecomSys/FM/img5.png" alt="FFM计算公式"><br>其中，fj 是第 j 个特征所属的field。如果隐向量的长度为 k，那么FFM的二次参数有 nfk 个，远多于FM模型的 nk 个。此外，由于隐向量与field相关，FFM二次项并不能够化简，其预测复杂度是 O(kn2)。</p>
<h4 id="区别"><a href="#区别" class="headerlink" title="区别"></a>区别</h4><blockquote>
<ol>
<li>FM和FFM模型的二次项的个数都是 n(n−1)&#x2F;2 个，区别在于FM模型中二次项<strong>存在重复使用的隐向量</strong>，而FFM模型没有，这正是由于FFM的域的概念的存在</li>
<li>FM模型的参数量为nk，FFM模型的参数量为nfk个</li>
<li>FM模型的时间复杂度可以优化为线性的，而FFM模型为nfk（最坏时，即当所有特征都是独自一个域时，为n^2k）</li>
</ol>
</blockquote>
<h4 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h4><p>在DSP或者推荐场景中，FFM主要用来评估站内的CTR和CVR，即一个用户对一个商品的潜在点击率和点击后的转化率。<br>CTR和CVR预估模型都是在线下训练，然后线上预测。两个模型采用的特征大同小异，主要分三类：</p>
<blockquote>
<ol>
<li>用户相关的特征: 年龄、性别、职业、兴趣、品类偏好、浏览&#x2F;购买品类等基本信息，以及用户近期点击量&#x2F;购买量&#x2F;消费额等统计信息</li>
<li>商品相关的特征: 商品所属品类、销量、价格、评分、历史CTR&#x2F;CVR等信息</li>
<li>用户-商品匹配特征: 浏览&#x2F;购买品类匹配、浏览&#x2F;购买商家匹配、兴趣偏好匹配等</li>
</ol>
</blockquote>
<p>为了使用FFM方法，所有的特征必须转换成“field_id:feat_id:value”格式，field_id代表特征所属field的编号，feat_id是特征编号，value是特征的值。数值型的特征比较容易处理，只需分配单独的field编号，如用户评论得分、商品的历史CTR&#x2F;CVR等。categorical特征需要经过One-Hot编码成数值型，编码产生的所有特征同属于一个field，而特征的值只能是0或1，如用户的性别、年龄段，商品的品类id等。除此之外，还有第三类特征，如用户浏览&#x2F;购买品类，有多个品类id且用一个数值衡量用户浏览或购买每个品类商品的数量。这类特征按照categorical特征处理，不同的只是特征的值不是0或1，而是代表用户浏览或购买数量的数值。按前述方法得到field_id之后，再对转换后特征顺序编号，得到feat_id，特征的值也可以按照之前的方法获得。 </p>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Recom/" rel="tag">Recom</a></li></ul>

    </footer>
  </div>

   
    
</article>

    
  </article>
  

  
  <nav class="page-nav">
    
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="extend next" rel="next" href="/page/2/">下一页</a>
  </nav>
  
</section>
</div>

      <footer class="footer">
  <div class="outer">
    <ul>
      <li>
        Copyrights &copy;
        2022
        <i class="ri-heart-fill heart_icon"></i> Xueru Wang
      </li>
    </ul>
    <ul>
      <li>
        
      </li>
    </ul>
    <ul>
      <li>
        
      </li>
    </ul>
    <ul>
      
    </ul>
    <ul>
      
    </ul>
    <ul>
      <li>
        <!-- cnzz统计 -->
        
        <script type="text/javascript" src='https://s9.cnzz.com/z_stat.php?id=1278069914&amp;web_id=1278069914'></script>
        
      </li>
    </ul>
  </div>
</footer>    
    </main>
    <div class="float_btns">
      <div class="totop" id="totop">
  <i class="ri-arrow-up-line"></i>
</div>

<div class="todark" id="todark">
  <i class="ri-moon-line"></i>
</div>

    </div>
    <aside class="sidebar on">
      <button class="navbar-toggle"></button>
<nav class="navbar">
  
  <div class="logo">
    <a href="/"><img src="/images/ayer-side.svg" alt="Alien笔记"></a>
  </div>
  
  <ul class="nav nav-main">
    
    <li class="nav-item">
      <a class="nav-item-link" href="/">主页</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/archives">归档</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/categories">分类</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags">标签</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/about">关于我</a>
    </li>
    
  </ul>
</nav>
<nav class="navbar navbar-bottom">
  <ul class="nav">
    <li class="nav-item">
      
      <a class="nav-item-link nav-item-search"  title="搜索">
        <i class="ri-search-line"></i>
      </a>
      
      
      <a class="nav-item-link" target="_blank" href="/atom.xml" title="RSS Feed">
        <i class="ri-rss-line"></i>
      </a>
      
    </li>
  </ul>
</nav>
<div class="search-form-wrap">
  <div class="local-search local-search-plugin">
  <input type="search" id="local-search-input" class="local-search-input" placeholder="Search...">
  <div id="local-search-result" class="local-search-result"></div>
</div>
</div>
    </aside>
    <div id="mask"></div>

<!-- #reward -->
<div id="reward">
  <span class="close"><i class="ri-close-line"></i></span>
  <p class="reward-p"><i class="ri-cup-line"></i>请我喝杯咖啡吧~</p>
  <div class="reward-box">
    
    <div class="reward-item">
      <img class="reward-img" src="/images/alipay.jpg">
      <span class="reward-type">支付宝</span>
    </div>
    
    
    <div class="reward-item">
      <img class="reward-img" src="/images/wechat.jpg">
      <span class="reward-type">微信</span>
    </div>
    
  </div>
</div>
    
<script src="/js/jquery-3.6.0.min.js"></script>
 
<script src="/js/lazyload.min.js"></script>

<!-- Tocbot -->

<script src="https://cdn.staticfile.org/jquery-modal/0.9.2/jquery.modal.min.js"></script>
<link
  rel="stylesheet"
  href="https://cdn.staticfile.org/jquery-modal/0.9.2/jquery.modal.min.css"
/>
<script src="https://cdn.staticfile.org/justifiedGallery/3.8.1/js/jquery.justifiedGallery.min.js"></script>

<script src="/dist/main.js"></script>

<!-- ImageViewer -->
 <!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" style="display:none" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo http://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>

<link rel="stylesheet" href="https://cdn.staticfile.org/photoswipe/4.1.3/photoswipe.min.css">
<link rel="stylesheet" href="https://cdn.staticfile.org/photoswipe/4.1.3/default-skin/default-skin.min.css">
<script src="https://cdn.staticfile.org/photoswipe/4.1.3/photoswipe.min.js"></script>
<script src="https://cdn.staticfile.org/photoswipe/4.1.3/photoswipe-ui-default.min.js"></script>

<script>
    function viewer_init() {
        let pswpElement = document.querySelectorAll('.pswp')[0];
        let $imgArr = document.querySelectorAll(('.article-entry img:not(.reward-img)'))

        $imgArr.forEach(($em, i) => {
            $em.onclick = () => {
                // slider展开状态
                // todo: 这样不好，后面改成状态
                if (document.querySelector('.left-col.show')) return
                let items = []
                $imgArr.forEach(($em2, i2) => {
                    let img = $em2.getAttribute('data-idx', i2)
                    let src = $em2.getAttribute('data-target') || $em2.getAttribute('src')
                    let title = $em2.getAttribute('alt')
                    // 获得原图尺寸
                    const image = new Image()
                    image.src = src
                    items.push({
                        src: src,
                        w: image.width || $em2.width,
                        h: image.height || $em2.height,
                        title: title
                    })
                })
                var gallery = new PhotoSwipe(pswpElement, PhotoSwipeUI_Default, items, {
                    index: parseInt(i)
                });
                gallery.init()
            }
        })
    }
    viewer_init()
</script> 
<!-- MathJax -->

<!-- Katex -->

<!-- busuanzi  -->

<!-- ClickLove -->

<!-- ClickBoom1 -->

<!-- ClickBoom2 -->

<!-- CodeCopy -->
 
<link rel="stylesheet" href="/css/clipboard.css">
 <script src="https://cdn.staticfile.org/clipboard.js/2.0.10/clipboard.min.js"></script>
<script>
  function wait(callback, seconds) {
    var timelag = null;
    timelag = window.setTimeout(callback, seconds);
  }
  !function (e, t, a) {
    var initCopyCode = function(){
      var copyHtml = '';
      copyHtml += '<button class="btn-copy" data-clipboard-snippet="">';
      copyHtml += '<i class="ri-file-copy-2-line"></i><span>COPY</span>';
      copyHtml += '</button>';
      $(".highlight .code pre").before(copyHtml);
      $(".article pre code").before(copyHtml);
      var clipboard = new ClipboardJS('.btn-copy', {
        target: function(trigger) {
          return trigger.nextElementSibling;
        }
      });
      clipboard.on('success', function(e) {
        let $btn = $(e.trigger);
        $btn.addClass('copied');
        let $icon = $($btn.find('i'));
        $icon.removeClass('ri-file-copy-2-line');
        $icon.addClass('ri-checkbox-circle-line');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPIED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('ri-checkbox-circle-line');
          $icon.addClass('ri-file-copy-2-line');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
      clipboard.on('error', function(e) {
        e.clearSelection();
        let $btn = $(e.trigger);
        $btn.addClass('copy-failed');
        let $icon = $($btn.find('i'));
        $icon.removeClass('ri-file-copy-2-line');
        $icon.addClass('ri-time-line');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPY FAILED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('ri-time-line');
          $icon.addClass('ri-file-copy-2-line');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
    }
    initCopyCode();
  }(window, document);
</script>
 
<!-- CanvasBackground -->

<script>
  if (window.mermaid) {
    mermaid.initialize({ theme: "forest" });
  }
</script>


    
    

  </div>
</body>

</html>